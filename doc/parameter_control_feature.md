# ThinkCloud for Web - 参数控制功能更新说明

## 📋 更新概述

本次更新为 ThinkCloud for Web（原 SimpleLLMFront）添加了**完整的模型参数控制功能**，并将项目更名为 **ThinkCloud for Web**。

更新时间：2025-12-01
版本：v2.1

---

## ✨ 新增功能

### 1. 系统提示词 (System Instruction)

**功能说明**：

- 允许用户为模型设置自定义的角色和行为规范
- 支持多行输入（3-5行）
- 留空时使用默认系统提示词："你是一个有帮助、诚实且无害的 AI 助手。"

**UI 位置**：

- 左侧控制面板 → "⚙️ 模型参数" 区域
- 标签：📝 System Instruction（系统提示词）

**使用示例**：

```
你是一位经验丰富的Python专家，擅长代码审查和性能优化。
请用简洁、专业的语言回答问题。
```

### 2. Temperature（温度）参数

**功能说明**：

- 控制生成文本的随机性
- 范围：0.0 - 2.0
- 默认值：0.7
- 步长：0.1

**效果**：

- 值越高（接近 2.0）：输出越随机、创造性更强
- 值越低（接近 0.0）：输出越确定、更保守

**UI 位置**：

- 左侧控制面板 → "⚙️ 模型参数" 区域
- 标签：🌡️ Temperature（温度）
- 类型：滑块控制

### 3. 高级参数（折叠区）

#### 3.1 Top P（核采样）

**功能说明**：

- 控制考虑的词汇范围
- 范围：0.0 - 1.0
- 默认值：0.9
- 步长：0.05

**效果**：

- 值越高：考虑更多的词汇选项
- 值越低：只考虑最可能的词汇

#### 3.2 Max Tokens（最大长度）

**功能说明**：

- 限制生成的最大 token 数量
- 范围：1 - 32,768
- 默认值：2,048
- 步长：256

**效果**：

- 控制回复的最大长度
- 防止超长输出消耗过多资源

#### 3.3 Frequency Penalty（频率惩罚）

**功能说明**：

- 降低重复词汇的频率
- 范围：-2.0 - 2.0
- 默认值：0.0
- 步长：0.1

**效果**：

- 正值：减少重复，输出更多样化
- 负值：增加重复
- 0：不惩罚

#### 3.4 Presence Penalty（存在惩罚）

**功能说明**：

- 鼓励模型谈论新主题
- 范围：-2.0 - 2.0
- 默认值：0.0
- 步长：0.1

**效果**：

- 正值：增加话题多样性，避免重复主题
- 负值：倾向于保持当前主题
- 0：不惩罚

---

## 🏗️ 技术实现

### 修改的文件

1. **`src/config.py`**
    - 新增 `MODEL_PARAMETERS` 配置字典
    - 新增 `DEFAULT_SYSTEM_INSTRUCTION` 常量
    - 定义所有参数的默认值、范围、步长和描述

2. **`src/providers.py`**
    - 更新 `BaseProvider.chat_completion()` 抽象方法签名
    - 更新所有提供商实现类：
        - `CerebrasProvider`
        - `DeepSeekProvider`
        - `OpenAIProvider`
        - `DashScopeProvider`
    - 支持接收和传递所有新增参数

3. **`src/api_service.py`**
    - 更新 `MultiProviderAPIService.chat_completion()` 方法
    - 传递所有参数给底层 provider

4. **`src/deep_think.py`**
    - 更新 `DeepThinkOrchestrator.__init__()` 方法
    - 新增参数存储：`system_instruction`, `temperature`, `top_p`, `max_tokens`
    - 更新 `_call_llm()` 方法传递参数

5. **`main.py`**
    - 添加所有参数的 UI 控件
    - 更新 `bot_message()` 函数接收和传递参数
    - 更新事件绑定
    - 项目更名为 **ThinkCloud for Web**

6. **`README.md`**
    - 更新项目名称
    - 新增参数控制功能说明
    - 更新界面说明

---

## 📊 UI 布局

### 左侧控制面板结构

```
┌─────────────────────────────────────┐
│ 🏢 选择提供商                       │
│ 🤖 选择模型                         │
│ ────────────────────────────────── │
│ 📊 系统状态                         │
│ ────────────────────────────────── │
│ ⚙️ 模型参数                        │
│   📝 System Instruction [文本框]   │
│   🌡️ Temperature [滑块]            │
│   🔧 高级参数 [折叠区]             │
│      🎯 Top P                      │
│      📏 Max Tokens                 │
│      🔁 Frequency Penalty          │
│      ✨ Presence Penalty           │
│ ────────────────────────────────── │
│ 🧠 深度思考模式                    │
│   ☑ 启用深度思考                  │
│   🔧 高级选项 [折叠区]            │
│      ☑ 启用自我审查               │
│      ☑ 显示思考过程               │
│      📊 最大子任务数               │
│ ────────────────────────────────── │
│ 💡 功能提示                        │
└─────────────────────────────────────┘
```

---

## 🔧 使用指南

### 基础使用

1. **调整 Temperature**：
   ```
   创造性写作：1.0 - 1.5
   技术问答：  0.3 - 0.7
   代码生成：  0.1 - 0.3
   ```

2. **设置 System Instruction**：
   ```
   示例1（代码专家）：
   你是一位资深软件工程师，精通Python、JavaScript和系统架构。
   回答时请注重代码质量和最佳实践。

   示例2（学习助手）：
   你是一位耐心的教师，擅长用通俗易懂的语言解释复杂概念。
   请使用比喻和例子帮助理解。
   ```

3. **控制输出长度**：
    - 简短回答：设置 Max Tokens = 512
    - 中等长度：设置 Max Tokens = 2048（默认）
    - 长篇详解：设置 Max Tokens = 4096+

### 高级技巧

1. **减少重复**：
    - Frequency Penalty = 0.5 - 1.0
    - 适用于创作、头脑风暴

2. **探索新话题**：
    - Presence Penalty = 0.5 - 1.0
    - 适用于研究、讨论

3. **组合使用**：
   ```
   场景：技术博客写作
   - Temperature: 0.8（适度创造性）
   - Top P: 0.9（保持多样性）
   - Max Tokens: 4096（允许长篇）
   - Frequency Penalty: 0.6（减少重复词汇）
   - Presence Penalty: 0.4（探索不同角度）
   - System Instruction: "你是一位技术博客作者..."
   ```

---

## ⚠️ 注意事项

### 提供商兼容性

1. **完全支持**：
    - Cerebras ✅
    - DeepSeek ✅
    - OpenAI ✅

2. **部分支持**：
    - DashScope（阿里云百炼）⚠️
        - 支持：temperature, top_p, max_tokens
        - 可能不支持：frequency_penalty, presence_penalty
        - 代码中已注释，如需启用请测试后取消注释

### 参数冲突

- Temperature 和 Top P 同时设置时可能产生交互效果
- 建议：优先调整 Temperature，Top P 保持默认值（0.9）

### 性能影响

- Max Tokens 越大，响应时间越长
- Frequency/Presence Penalty 可能略微增加计算时间

---

## 🧪 测试建议

### 测试检查清单

- [ ] System Instruction 生效（观察回复风格变化）
- [ ] Temperature 调节有效（0.1 vs 1.5 对比）
- [ ] Max Tokens 限制生效（设置 256 测试短回复）
- [ ] 高级参数正常工作
- [ ] 深度思考模式兼容新参数
- [ ] 所有提供商正常调用

### 测试命令

```bash
# 语法验证
python -m py_compile main.py src/*.py

# 启动应用
python main.py

# 测试参数传递（检查日志输出）
# 开启 verbose 模式观察 API 调用
```

---

## 📈 未来改进方向

### 短期（已计划）

- [ ] 参数预设方案（快速切换场景）
- [ ] 参数历史记录
- [ ] 参数效果实时预览

### 中期

- [ ] 不同模型的推荐参数
- [ ] 参数自动调优
- [ ] A/B 测试工具

### 长期

- [ ] 参数影响可视化
- [ ] 智能参数建议系统
- [ ] 多模型参数对比

---

## 🐛 已知问题

1. **DashScope Penalty 参数**：
    - 状态：未确认是否支持
    - 解决：需要实际测试验证
    - 位置：`src/providers.py:354-359`

2. **深度思考参数传递**：
    - 状态：部分参数未传递到深度思考模式
    - 影响：深度思考时部分参数可能不生效
    - 计划：在未来版本中完善

---

## 📞 支持

如遇问题，请检查：

1. 控制台日志输出
2. API 密钥配置
3. 提供商兼容性说明

---

**更新完成！** 🎉

ThinkCloud for Web 现已支持完整的模型参数控制，让您的 AI 对话更加灵活和强大！
