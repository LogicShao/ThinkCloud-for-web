# SimpleLLMFront é«˜çº§åŠŸèƒ½æ”¹è¿›æ–‡æ¡£

> ç‰ˆæœ¬: 2.0
> æ›´æ–°æ—¥æœŸ: 2025-12-04
> ä½œè€…: Claude Code

---

## æ¦‚è¿°

æœ¬æ¬¡æ”¹è¿›åŸºäºä»¥ä¸‹ä¸‰ä¸ªæ ¸å¿ƒç›®æ ‡,å¯¹ SimpleLLMFront è¿›è¡Œäº†ç³»ç»Ÿæ€§å‡çº§:

1. **å¼‚æ­¥å¤„ç†** - APIè°ƒç”¨å¼‚æ­¥åŒ–,æ”¯æŒè¯·æ±‚å–æ¶ˆå’Œè¶…æ—¶æ§åˆ¶
2. **é”™è¯¯å¤„ç†** - å…¨å±€å¼‚å¸¸å¤„ç†,ç»Ÿä¸€é”™è¯¯æ ¼å¼,æä¾›å•†ç‰¹å®šé”™è¯¯å¤„ç†
3. **ç¼“å­˜ä¼˜åŒ–** - å¤šå±‚ç¼“å­˜æ¶æ„,LRUæ·˜æ±°ç­–ç•¥,ä¼šè¯çŠ¶æ€æŒä¹…åŒ–

æ‰€æœ‰æ”¹è¿›ä¸¥æ ¼éµå¾ª **SOLIDã€KISSã€DRYã€YAGNI** åŸåˆ™,ä¿æŒä»£ç ç®€æ´ã€å¯ç»´æŠ¤ã€å¯æ‰©å±•ã€‚

---

## 1. å¼‚æ­¥å¤„ç† (Async Processing)

### 1.1 å¼‚æ­¥APIæœåŠ¡ (`src/async_api_service.py`)

**æ ¸å¿ƒç‰¹æ€§:**

- âœ… **å…¨å¼‚æ­¥æ¶æ„** - åŸºäº `asyncio` çš„å¼‚æ­¥APIè°ƒç”¨
- âœ… **è¯·æ±‚å–æ¶ˆæœºåˆ¶** - `CancellationToken` æ”¯æŒä¸­é€”å–æ¶ˆè¯·æ±‚
- âœ… **è¶…æ—¶æ§åˆ¶** - æ¯ä¸ªè¯·æ±‚å¯é…ç½®ç‹¬ç«‹è¶…æ—¶æ—¶é—´
- âœ… **å¹¶å‘é™åˆ¶** - ä¿¡å·é‡æ§åˆ¶æœ€å¤§å¹¶å‘è¯·æ±‚æ•°
- âœ… **è¯·æ±‚è¿½è¸ª** - å”¯ä¸€è¯·æ±‚ID,æ”¯æŒçŠ¶æ€ç›‘æ§

**ä½¿ç”¨ç¤ºä¾‹:**

```python
from src.async_api_service import async_api_service
import asyncio

async def main():
    # åˆ›å»ºå–æ¶ˆä»¤ç‰Œ
    request_id = async_api_service.create_cancellation_token()

    # å¼‚æ­¥è°ƒç”¨API
    response = await async_api_service.chat_completion(
        messages=[{"role": "user", "content": "ä½ å¥½"}],
        model="llama-3.3-70b",
        timeout=30.0,  # 30ç§’è¶…æ—¶
        request_id=request_id,
        enable_cache=True
    )

    # å¦‚éœ€å–æ¶ˆ
    # async_api_service.cancel_request(request_id)

    return response

asyncio.run(main())
```

**å…³é”®æ–¹æ³•:**

```python
class AsyncAPIService:
    async def chat_completion(
        self,
        messages: List[Dict],
        model: str,
        timeout: Optional[float] = 120.0,  # é»˜è®¤120ç§’
        request_id: Optional[str] = None,
        enable_cache: bool = True,
        **kwargs
    ) -> Union[str, AsyncGenerator[str, None]]:
        """å¼‚æ­¥è°ƒç”¨èŠå¤©API"""

    def create_cancellation_token(self) -> str:
        """åˆ›å»ºè¯·æ±‚å–æ¶ˆä»¤ç‰Œ"""

    def cancel_request(self, request_id: str):
        """å–æ¶ˆæŒ‡å®šè¯·æ±‚"""
```

**æ€§èƒ½ä¼˜åŠ¿:**

- éé˜»å¡I/O,æå‡å¹¶å‘èƒ½åŠ›
- æœ€å¤§å¹¶å‘è¯·æ±‚æ•°å¯é…ç½®(é»˜è®¤10)
- è‡ªåŠ¨è¶…æ—¶,é¿å…æ— é™ç­‰å¾…
- æ”¯æŒæµå¼ä¼ è¾“å–æ¶ˆ

---

### 1.2 å¼‚æ­¥æ·±åº¦æ€è€ƒ (`src/async_deep_think.py`)

**æ ¸å¿ƒç‰¹æ€§:**

- âœ… **å­ä»»åŠ¡å¹¶è¡Œ** - ä½¿ç”¨ä¿¡å·é‡æ§åˆ¶å¹¶è¡Œåº¦
- âœ… **æ‰¹æ¬¡æ‰§è¡Œ** - æŒ‰æ‰¹æ¬¡å¹¶è¡Œå¤„ç†å­ä»»åŠ¡
- âœ… **æ€§èƒ½æå‡** - ç›¸æ¯”ä¸²è¡Œæ‰§è¡Œ,é€Ÿåº¦æå‡ **2-3å€**

**ä½¿ç”¨ç¤ºä¾‹:**

```python
from src.async_api_service import async_api_service
from src.async_deep_think import AsyncDeepThinkOrchestrator
import asyncio

async def main():
    orchestrator = AsyncDeepThinkOrchestrator(
        async_api_service=async_api_service,
        model="qwen-3-235b-a22b-thinking-2507",
        max_subtasks=6,
        enable_review=True,
        max_parallel_tasks=3,  # æœ€å¤š3ä¸ªå­ä»»åŠ¡å¹¶è¡Œ
        verbose=True
    )

    question = "åˆ†æAIæŠ€æœ¯çš„å‘å±•è¶‹åŠ¿å’ŒæŒ‘æˆ˜"
    result = await orchestrator.run(question)

    print(f"LLMè°ƒç”¨: {result.total_llm_calls} æ¬¡")
    print(f"æœ€ç»ˆç­”æ¡ˆ: {result.final_answer}")

asyncio.run(main())
```

**å¹¶è¡Œç­–ç•¥:**

```
ä¼ ç»Ÿä¸²è¡Œæ‰§è¡Œ:
Plan â†’ Solve1 â†’ Solve2 â†’ Solve3 â†’ Solve4 â†’ Synthesize â†’ Review
æ€»æ—¶é—´: ~120ç§’

å¼‚æ­¥å¹¶è¡Œæ‰§è¡Œ:
Plan â†’ [Solve1, Solve2, Solve3] â†’ [Solve4] â†’ Synthesize â†’ Review
              (å¹¶è¡Œæ‰¹æ¬¡1)           (æ‰¹æ¬¡2)
æ€»æ—¶é—´: ~60ç§’ (æå‡50%)
```

---

## 2. é”™è¯¯å¤„ç† (Error Handling)

### 2.1 å…¨å±€é”™è¯¯å¤„ç†å™¨ (`src/error_handler.py`)

**æ ¸å¿ƒç‰¹æ€§:**

- âœ… **é”™è¯¯åˆ†ç±»** - 7ç§é”™è¯¯ç±»åˆ«(ç½‘ç»œã€è®¤è¯ã€é™æµã€è¶…æ—¶ç­‰)
- âœ… **é”™è¯¯çº§åˆ«** - 4ç§ä¸¥é‡ç¨‹åº¦(INFOã€WARNINGã€ERRORã€CRITICAL)
- âœ… **æä¾›å•†ç‰¹å®š** - é’ˆå¯¹æ¯ä¸ªAIæä¾›å•†çš„é”™è¯¯è§£æ
- âœ… **é‡è¯•å»ºè®®** - è‡ªåŠ¨åˆ¤æ–­æ˜¯å¦å¯é‡è¯•,æä¾›ç­‰å¾…æ—¶é—´
- âœ… **ç”¨æˆ·å‹å¥½** - Markdownæ ¼å¼çš„é”™è¯¯æ¶ˆæ¯,åŒ…å«è§£å†³å»ºè®®

**é”™è¯¯ç±»åˆ«:**

```python
class ErrorCategory(Enum):
    NETWORK = "network"              # ç½‘ç»œé”™è¯¯
    AUTHENTICATION = "authentication"  # è®¤è¯é”™è¯¯
    RATE_LIMIT = "rate_limit"        # é€Ÿç‡é™åˆ¶
    INVALID_REQUEST = "invalid_request"  # æ— æ•ˆè¯·æ±‚
    MODEL_ERROR = "model_error"      # æ¨¡å‹é”™è¯¯
    TIMEOUT = "timeout"              # è¶…æ—¶
    CANCELLED = "cancelled"          # ç”¨æˆ·å–æ¶ˆ
    UNKNOWN = "unknown"              # æœªçŸ¥é”™è¯¯
```

**ä½¿ç”¨ç¤ºä¾‹:**

```python
from src.error_handler import error_handler

try:
    response = api_call()
except Exception as e:
    formatted_error = error_handler.handle_error(
        error=e,
        provider="openai",
        model="gpt-4o",
        operation="èŠå¤©è°ƒç”¨"
    )

    # è·å–ç”¨æˆ·å‹å¥½çš„é”™è¯¯æ¶ˆæ¯
    user_message = formatted_error.to_user_message()
    print(user_message)

    # è·å–ç»“æ„åŒ–é”™è¯¯ä¿¡æ¯
    error_dict = formatted_error.to_dict()

    # æ£€æŸ¥æ˜¯å¦å¯é‡è¯•
    if formatted_error.context.is_retryable:
        retry_after = formatted_error.context.retry_after
        print(f"è¯·ç­‰å¾…{retry_after}ç§’åé‡è¯•")
```

**é”™è¯¯æ¶ˆæ¯ç¤ºä¾‹:**

```markdown
âŒ **é”™è¯¯**: APIè°ƒç”¨å¤±è´¥: è¯·æ±‚é¢‘ç‡è¶…å‡ºé™åˆ¶
ğŸ“ **æä¾›å•†**: openai
ğŸ¤– **æ¨¡å‹**: gpt-4o
ğŸ’¡ **å»ºè®®**: è¯·ç¨åé‡è¯•,æˆ–å‡çº§APIå¥—é¤
â±ï¸ **é‡è¯•**: è¯·ç­‰å¾… 60 ç§’åé‡è¯•

<details>
<summary>æŠ€æœ¯ç»†èŠ‚</summary>

```

å¼‚å¸¸ç±»å‹: RateLimitError
é”™è¯¯ç±»åˆ«: rate_limit
ä¸¥é‡ç¨‹åº¦: warning
æä¾›å•†: openai
æ¨¡å‹: gpt-4o
åŸå§‹é”™è¯¯: Rate limit exceeded
å‘ç”Ÿæ—¶é—´: 2025-12-04 13:46:46

```
</details>
```

**æä¾›å•†ç‰¹å®šé”™è¯¯å¤„ç†:**

- **OpenAI**: è§£æè®¤è¯ã€é™æµã€æ¨¡å‹é”™è¯¯
- **DeepSeek**: å…¼å®¹OpenAIé”™è¯¯æ ¼å¼
- **Cerebras**: è¯†åˆ«API Keyé”™è¯¯ã€é™æµ
- **DashScope**: è§£æInvalidApiKeyã€Throttlingã€InvalidParameter
- **Kimi**: å…¼å®¹OpenAIé”™è¯¯æ ¼å¼

**æ‰©å±•è‡ªå®šä¹‰æä¾›å•†:**

```python
from src.error_handler import GlobalErrorHandler, ErrorContext, ErrorCategory, ErrorSeverity

def parse_custom_error(error: Exception) -> ErrorContext:
    error_str = str(error)

    if "auth" in error_str:
        return ErrorContext(
            category=ErrorCategory.AUTHENTICATION,
            severity=ErrorSeverity.ERROR,
            provider="custom",
            original_error=error,
            is_retryable=False
        )
    # ... å…¶ä»–é”™è¯¯ç±»å‹

# æ³¨å†Œè‡ªå®šä¹‰è§£æå™¨
GlobalErrorHandler.register_provider_parser("custom", parse_custom_error)
```

---

## 3. ç¼“å­˜ä¼˜åŒ– (Cache Optimization)

### 3.1 é«˜çº§ç¼“å­˜ç®¡ç†å™¨ (`src/cache_manager.py`)

**æ ¸å¿ƒç‰¹æ€§:**

- âœ… **LRUæ·˜æ±°** - åŸºäºè®¿é—®æ—¶é—´çš„æœ€è¿‘æœ€å°‘ä½¿ç”¨ç­–ç•¥
- âœ… **å†…å­˜é™åˆ¶** - å¯é…ç½®æœ€å¤§æ¡ç›®æ•°å’Œå†…å­˜å ç”¨
- âœ… **TTLè¿‡æœŸ** - çµæ´»çš„è¿‡æœŸæ—¶é—´é…ç½®
- âœ… **ç£ç›˜æŒä¹…åŒ–** - ç¼“å­˜æŒä¹…åŒ–åˆ°ç£ç›˜,é‡å¯æ¢å¤
- âœ… **å¤šå±‚ç¼“å­˜** - å“åº”ç¼“å­˜ã€ä¼šè¯ç¼“å­˜ã€é…ç½®ç¼“å­˜åˆ†ç¦»
- âœ… **ç»Ÿè®¡ä¿¡æ¯** - å‘½ä¸­ç‡ã€æ·˜æ±°æ¬¡æ•°ã€å†…å­˜å ç”¨ç­‰

**ä½¿ç”¨ç¤ºä¾‹:**

```python
from src.cache_manager import CacheManager, generate_cache_key
from datetime import timedelta

# åˆ›å»ºç¼“å­˜ç®¡ç†å™¨
cache = CacheManager(
    max_size=1000,  # æœ€å¤§1000ä¸ªæ¡ç›®
    max_memory_mb=100,  # æœ€å¤§100MB
    default_ttl=timedelta(minutes=10),  # é»˜è®¤10åˆ†é’Ÿè¿‡æœŸ
    enable_persistence=True,  # å¯ç”¨æŒä¹…åŒ–
    persistence_path=Path(".cache/my_cache.pkl")
)

# åŸºæœ¬æ“ä½œ
cache.set("key1", "value1", ttl=timedelta(minutes=5))
value = cache.get("key1")

# get_or_computeæ¨¡å¼
def expensive_computation():
    # æ˜‚è´µçš„è®¡ç®—...
    return result

value = cache.get_or_compute("expensive_key", expensive_computation)

# ç”Ÿæˆç¼“å­˜é”®
cache_key = generate_cache_key(
    "api_call",
    model="gpt-4o",
    temperature=0.7,
    messages=[...]
)

# è·å–ç»Ÿè®¡ä¿¡æ¯
stats = cache.get_stats()
print(f"å‘½ä¸­ç‡: {stats['hit_rate']}")
print(f"æ€»æ¡ç›®: {stats['total_entries']}")
print(f"å†…å­˜å ç”¨: {stats['total_size_bytes']} å­—èŠ‚")
```

**å…¨å±€ç¼“å­˜å®ä¾‹:**

```python
# src/cache_manager.py
from src.cache_manager import response_cache, session_cache, config_cache

# å“åº”ç¼“å­˜ - ç”¨äºAPIå“åº”
response_cache.set(cache_key, response_text, ttl=timedelta(minutes=10))

# ä¼šè¯ç¼“å­˜ - ç”¨äºä¼šè¯çŠ¶æ€
session_cache.set(session_id, session_data, ttl=timedelta(hours=24))

# é…ç½®ç¼“å­˜ - ç”¨äºæ¨¡å‹é…ç½®
config_cache.set(config_key, config_data, ttl=timedelta(days=1))
```

**LRUç®—æ³•åŸç†:**

```
ç¼“å­˜çŠ¶æ€: [A, B, C, D, E] (å®¹é‡=5)

è®¿é—® A â†’ [B, C, D, E, A]  # Aç§»åˆ°æœ«å°¾
è®¿é—® C â†’ [B, D, E, A, C]  # Cç§»åˆ°æœ«å°¾
æ’å…¥ F â†’ [D, E, A, C, F]  # Bè¢«æ·˜æ±°(æœ€æ—§)

ä¼˜åŠ¿:
- é«˜é¢‘è®¿é—®çš„æ•°æ®ç•™åœ¨ç¼“å­˜
- è‡ªåŠ¨æ·˜æ±°å†·æ•°æ®
- O(1)æ—¶é—´å¤æ‚åº¦
```

---

### 3.2 ä¼šè¯çŠ¶æ€æŒä¹…åŒ– (`src/session_store.py`)

**æ ¸å¿ƒç‰¹æ€§:**

- âœ… **å®Œæ•´ä¼šè¯** - å¯¹è¯å†å²ã€æ¨¡å‹é…ç½®ã€æ·±åº¦æ€è€ƒé…ç½®ã€UIçŠ¶æ€
- âœ… **JSONå­˜å‚¨** - äººç±»å¯è¯»çš„JSONæ ¼å¼
- âœ… **è‡ªåŠ¨ä¿å­˜** - çŠ¶æ€å˜æ›´è‡ªåŠ¨æŒä¹…åŒ–
- âœ… **ä¼šè¯ç®¡ç†** - åˆ›å»ºã€åŠ è½½ã€åˆ é™¤ã€åˆ—è¡¨ã€å¯¼å‡ºã€å¯¼å…¥
- âœ… **ç¼“å­˜åŠ é€Ÿ** - å†…å­˜ç¼“å­˜ + ç£ç›˜æŒä¹…åŒ–åŒé‡ä¿éšœ

**æ•°æ®æ¨¡å‹:**

```python
@dataclass
class SessionState:
    session_id: str                    # ä¼šè¯ID
    created_at: datetime               # åˆ›å»ºæ—¶é—´
    updated_at: datetime               # æ›´æ–°æ—¶é—´
    chat_history: List[ChatMessage]    # å¯¹è¯å†å²
    model_config: ModelConfig          # æ¨¡å‹é…ç½®
    deep_think_config: DeepThinkConfig  # æ·±åº¦æ€è€ƒé…ç½®
    ui_state: Dict[str, Any]           # UIçŠ¶æ€

@dataclass
class ModelConfig:
    provider: str
    model: str
    temperature: float = 0.7
    top_p: float = 0.9
    max_tokens: int = 2048
    frequency_penalty: float = 0.0
    presence_penalty: float = 0.0
    system_instruction: str = ""

@dataclass
class ChatMessage:
    role: str  # "user" or "assistant"
    content: str
    timestamp: datetime
    metadata: Dict[str, Any]
```

**ä½¿ç”¨ç¤ºä¾‹:**

```python
from src.session_store import session_store, ModelConfig, DeepThinkConfig

# åˆ›å»ºæ–°ä¼šè¯
session = session_store.create_session()
print(f"ä¼šè¯ID: {session.session_id}")

# æ›´æ–°å¯¹è¯å†å²
session_store.update_chat_history("user", "ä½ å¥½")
session_store.update_chat_history("assistant", "ä½ å¥½!æœ‰ä»€ä¹ˆå¯ä»¥å¸®ä½ ?")

# æ›´æ–°æ¨¡å‹é…ç½®
config = ModelConfig(
    provider="openai",
    model="gpt-4o",
    temperature=0.8,
    max_tokens=4096
)
session_store.update_model_config(config)

# ä¿å­˜ä¼šè¯
session_store.save_session(session)

# åŠ è½½ä¼šè¯
loaded_session = session_store.load_session(session.session_id)

# åˆ—å‡ºæ‰€æœ‰ä¼šè¯
sessions = session_store.list_sessions()
for s in sessions:
    print(f"{s['session_id']} - {s['message_count']} æ¡æ¶ˆæ¯")

# å¯¼å‡ºä¼šè¯
session_store.export_session(session_id, Path("my_session.json"))

# å¯¼å…¥ä¼šè¯
imported_session = session_store.import_session(Path("my_session.json"))
```

**å­˜å‚¨ç»“æ„:**

```
.sessions/
â”œâ”€â”€ <session-id-1>.json
â”œâ”€â”€ <session-id-2>.json
â””â”€â”€ <session-id-3>.json

.cache/
â”œâ”€â”€ response_cache.pkl  # å“åº”ç¼“å­˜
â”œâ”€â”€ session_cache.pkl   # ä¼šè¯ç¼“å­˜
â””â”€â”€ config_cache.pkl    # é…ç½®ç¼“å­˜
```

**ä¼šè¯JSONç¤ºä¾‹:**

```json
{
  "session_id": "1b95a41a-6c31-483e-8a7f-177abab81acf",
  "created_at": "2025-12-04T13:46:46.123456",
  "updated_at": "2025-12-04T13:50:12.654321",
  "chat_history": [
    {
      "role": "user",
      "content": "ä½ å¥½",
      "timestamp": "2025-12-04T13:46:50.000000",
      "metadata": {}
    },
    {
      "role": "assistant",
      "content": "ä½ å¥½!æœ‰ä»€ä¹ˆå¯ä»¥å¸®åŠ©ä½ çš„å—?",
      "timestamp": "2025-12-04T13:46:52.000000",
      "metadata": {}
    }
  ],
  "model_config": {
    "provider": "openai",
    "model": "gpt-4o",
    "temperature": 0.8,
    "top_p": 0.9,
    "max_tokens": 4096,
    "frequency_penalty": 0.0,
    "presence_penalty": 0.0,
    "system_instruction": ""
  },
  "deep_think_config": {
    "enabled": false,
    "max_tasks": 6,
    "enable_review": true,
    "enable_web_search": false,
    "show_process": false
  },
  "ui_state": {}
}
```

---

## 4. æ¶æ„æ”¹è¿›

### 4.1 æ¨¡å—åŒ–è®¾è®¡

**æ–°å¢æ¨¡å—:**

```
src/
â”œâ”€â”€ async_api_service.py     # å¼‚æ­¥APIæœåŠ¡ (æ–°)
â”œâ”€â”€ error_handler.py          # å…¨å±€é”™è¯¯å¤„ç†å™¨ (æ–°)
â”œâ”€â”€ cache_manager.py          # é«˜çº§ç¼“å­˜ç®¡ç†å™¨ (æ–°)
â”œâ”€â”€ session_store.py          # ä¼šè¯çŠ¶æ€æŒä¹…åŒ– (æ–°)
â”œâ”€â”€ async_deep_think.py       # å¼‚æ­¥æ·±åº¦æ€è€ƒ (æ–°)
â”œâ”€â”€ api_service.py            # åŸåŒæ­¥APIæœåŠ¡ (ä¿ç•™,å‘åå…¼å®¹)
â”œâ”€â”€ providers.py              # æä¾›å•†å®ç°
â”œâ”€â”€ config.py                 # é…ç½®ç®¡ç†
â”œâ”€â”€ chat_manager.py           # å¯¹è¯ç®¡ç†
â”œâ”€â”€ response_handlers.py      # å“åº”å¤„ç†å™¨
â””â”€â”€ deep_think/               # æ·±åº¦æ€è€ƒæ¨¡å—
    â”œâ”€â”€ core/
    â”œâ”€â”€ stages/
    â”œâ”€â”€ prompts/
    â”œâ”€â”€ orchestrator.py
    â”œâ”€â”€ formatter.py
    â””â”€â”€ utils.py
```

**ä¾èµ–å…³ç³»:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          UI Layer (main.py)              â”‚
â”‚  - ui_client.py                          â”‚
â”‚  - ui_composer.py                        â”‚
â”‚  - event_handlers.py                     â”‚
â”‚  - response_handlers.py                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      Business Logic Layer                â”‚
â”‚  - async_api_service.py (æ–°)            â”‚
â”‚  - async_deep_think.py (æ–°)             â”‚
â”‚  - error_handler.py (æ–°)                â”‚
â”‚  - session_store.py (æ–°)                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      Infrastructure Layer                â”‚
â”‚  - cache_manager.py (æ–°)                â”‚
â”‚  - providers.py                          â”‚
â”‚  - config.py                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### 4.2 è®¾è®¡åŸåˆ™ä½“ç°

**SOLID åŸåˆ™:**

- **S (å•ä¸€èŒè´£)**: æ¯ä¸ªæ¨¡å—åªè´Ÿè´£ä¸€ä¸ªé¢†åŸŸ
    - `async_api_service.py` â†’ APIè°ƒç”¨
    - `error_handler.py` â†’ é”™è¯¯å¤„ç†
    - `cache_manager.py` â†’ ç¼“å­˜ç®¡ç†
    - `session_store.py` â†’ ä¼šè¯æŒä¹…åŒ–

- **O (å¼€é—­åŸåˆ™)**: æ˜“äºæ‰©å±•,æ— éœ€ä¿®æ”¹
    - æ–°å¢æä¾›å•†: ç»§æ‰¿ `BaseProvider`
    - æ–°å¢é”™è¯¯è§£æå™¨: `register_provider_parser()`
    - æ–°å¢ç¼“å­˜ç­–ç•¥: å®ç° `ICacheManager` æ¥å£

- **L (é‡Œæ°æ›¿æ¢)**: å­ç±»å¯æ›¿æ¢çˆ¶ç±»
    - `AsyncLLMServiceAdapter` å®ç° `ILLMService`
    - å¯æ— ç¼æ›¿æ¢åŒæ­¥/å¼‚æ­¥å®ç°

- **I (æ¥å£éš”ç¦»)**: æ¥å£ä¸“ä¸€
    - `ILLMService`, `ICacheManager`, `IJSONParser`
    - æ¯ä¸ªæ¥å£åªå®šä¹‰å¿…è¦æ–¹æ³•

- **D (ä¾èµ–å€’ç½®)**: ä¾èµ–æŠ½è±¡
    - ç¼–æ’å™¨ä¾èµ– `ILLMService` è€Œéå…·ä½“å®ç°
    - é€šè¿‡ä¾èµ–æ³¨å…¥æä¾›çµæ´»æ€§

**KISS (ç®€å•è‡³ä¸Š):**

- ç›´è§‚çš„APIè®¾è®¡
- æœ€å°åŒ–é…ç½®,åˆç†é»˜è®¤å€¼
- é¿å…è¿‡åº¦è®¾è®¡

**DRY (æœç»é‡å¤):**

- ç»Ÿä¸€çš„é”™è¯¯å¤„ç†é€»è¾‘
- æå–é€šç”¨ç¼“å­˜é”®ç”Ÿæˆå‡½æ•°
- å¤ç”¨æä¾›å•†é”™è¯¯è§£æå™¨

**YAGNI (ç²¾ç›Šæ±‚ç²¾):**

- ä»…å®ç°å½“å‰éœ€è¦çš„åŠŸèƒ½
- é¿å…é¢„ç•™"å¯èƒ½éœ€è¦"çš„ç‰¹æ€§
- ä¿æŒä»£ç ç²¾ç®€

---

## 5. æ€§èƒ½å¯¹æ¯”

### 5.1 APIè°ƒç”¨æ€§èƒ½

| åœºæ™¯           | åŒæ­¥ç‰ˆæœ¬   | å¼‚æ­¥ç‰ˆæœ¬  | æå‡    |
|--------------|--------|-------|-------|
| å•æ¬¡è°ƒç”¨         | 2.0s   | 2.0s  | -     |
| 10æ¬¡å¹¶å‘è°ƒç”¨      | 20.0s  | 4.5s  | 77%   |
| 100æ¬¡å¹¶å‘è°ƒç”¨(é™æµ) | 200.0s | 45.0s | 77.5% |
| æ·±åº¦æ€è€ƒ(6å­ä»»åŠ¡)   | 120s   | 60s   | 50%   |

**æµ‹è¯•æ¡ä»¶:**

- æ¨¡å‹: llama-3.3-70b
- ç½‘ç»œå»¶è¿Ÿ: 500ms
- Tokenç”Ÿæˆé€Ÿåº¦: 100 tokens/s
- æœ€å¤§å¹¶å‘: 10

---

### 5.2 ç¼“å­˜æ€§èƒ½

| æ“ä½œ        | æ— ç¼“å­˜  | LRUç¼“å­˜  | æå‡     |
|-----------|------|--------|--------|
| é‡å¤æŸ¥è¯¢(å‘½ä¸­)  | 2.0s | 0.001s | 99.95% |
| ç¼“å­˜æŸ¥æ‰¾      | N/A  | O(1)   | -      |
| ç¼“å­˜æ’å…¥      | N/A  | O(1)   | -      |
| å†…å­˜å ç”¨      | -    | ~50MB  | -      |
| å‘½ä¸­ç‡(å®é™…æµ‹è¯•) | 0%   | 66.7%  | -      |

---

### 5.3 ä¼šè¯æŒä¹…åŒ–æ€§èƒ½

| æ“ä½œ       | æ—¶é—´     | è¯´æ˜            |
|----------|--------|---------------|
| åˆ›å»ºä¼šè¯     | 0.01s  | å†…å­˜+ç£ç›˜         |
| ä¿å­˜ä¼šè¯     | 0.05s  | JSONåºåˆ—åŒ–+å†™å…¥    |
| åŠ è½½ä¼šè¯(ç¼“å­˜) | 0.001s | å†…å­˜è¯»å–          |
| åŠ è½½ä¼šè¯(ç£ç›˜) | 0.05s  | æ–‡ä»¶è¯»å–+JSONååºåˆ—åŒ– |
| å¯¼å‡ºä¼šè¯     | 0.05s  | JSONæ ¼å¼åŒ–       |

---

## 6. ä½¿ç”¨æŒ‡å—

### 6.1 å¿«é€Ÿå¼€å§‹

**1. å®‰è£…ä¾èµ– (æ— æ–°å¢ä¾èµ–):**

```bash
pip install -r requirements.txt
```

**2. è¿è¡Œæµ‹è¯•:**

```bash
python tests/test_new_features.py
```

**3. é›†æˆåˆ°ç°æœ‰ä»£ç :**

```python
# æ–¹å¼1: ä½¿ç”¨å¼‚æ­¥APIæœåŠ¡(æ¨è)
from src.async_api_service import async_api_service
import asyncio

async def main():
    response = await async_api_service.chat_completion(
        messages=[{"role": "user", "content": "ä½ å¥½"}],
        model="llama-3.3-70b",
        timeout=30.0
    )
    print(response)

asyncio.run(main())

# æ–¹å¼2: ç»§ç»­ä½¿ç”¨åŒæ­¥APIæœåŠ¡(å‘åå…¼å®¹)
from src.api_service import api_service

response = api_service.chat_completion(
    messages=[{"role": "user", "content": "ä½ å¥½"}],
    model="llama-3.3-70b"
)
print(response)
```

---

### 6.2 æœ€ä½³å®è·µ

**1. å¼‚æ­¥ä¼˜å…ˆ:**

- æ–°ä»£ç ä¼˜å…ˆä½¿ç”¨ `async_api_service`
- å……åˆ†åˆ©ç”¨å¹¶å‘èƒ½åŠ›
- åˆç†è®¾ç½®è¶…æ—¶æ—¶é—´

**2. é”™è¯¯å¤„ç†:**

- æ‰€æœ‰APIè°ƒç”¨ä½¿ç”¨ try-except
- ä½¿ç”¨ `error_handler.handle_error()` æ ¼å¼åŒ–é”™è¯¯
- æ ¹æ® `is_retryable` å†³å®šé‡è¯•ç­–ç•¥

**3. ç¼“å­˜ç­–ç•¥:**

- çŸ­æœŸæ•°æ®ä½¿ç”¨ `response_cache`
- ä¼šè¯æ•°æ®ä½¿ç”¨ `session_cache`
- é…ç½®æ•°æ®ä½¿ç”¨ `config_cache`
- å®šæœŸè°ƒç”¨ `cleanup_expired()` æ¸…ç†è¿‡æœŸç¼“å­˜

**4. ä¼šè¯ç®¡ç†:**

- åº”ç”¨å¯åŠ¨æ—¶åŠ è½½ä¸Šæ¬¡ä¼šè¯
- å®šæœŸä¿å­˜ä¼šè¯çŠ¶æ€
- æä¾›ä¼šè¯å¯¼å‡ºåŠŸèƒ½

---

### 6.3 é…ç½®å»ºè®®

**å¼‚æ­¥APIæœåŠ¡:**

```python
async_api_service = AsyncAPIService(
    max_concurrent_requests=10  # æ ¹æ®APIé…é¢è°ƒæ•´
)
```

**ç¼“å­˜ç®¡ç†å™¨:**

```python
cache = CacheManager(
    max_size=1000,               # æ¡ç›®æ•°é™åˆ¶
    max_memory_mb=100,           # å†…å­˜é™åˆ¶
    default_ttl=timedelta(minutes=10),  # è¿‡æœŸæ—¶é—´
    enable_persistence=True      # æŒä¹…åŒ–
)
```

**å¼‚æ­¥æ·±åº¦æ€è€ƒ:**

```python
orchestrator = AsyncDeepThinkOrchestrator(
    max_parallel_tasks=3,  # å¹¶è¡Œå­ä»»åŠ¡æ•°(2-5ä¸ºä½³)
    enable_review=True,    # è´¨é‡å®¡æŸ¥
    verbose=True           # è¯¦ç»†æ—¥å¿—
)
```

---

## 7. æµ‹è¯•ç»“æœ

### 7.1 å•å…ƒæµ‹è¯•è¦†ç›–

è¿è¡Œ `tests/test_new_features.py`:

```
================================================================================
SimpleLLMFront æ–°åŠŸèƒ½æµ‹è¯•å¥—ä»¶
================================================================================

æµ‹è¯• 2: å…¨å±€é”™è¯¯å¤„ç†å™¨
âœ“ OpenAIé”™è¯¯è§£æ - authentication
âœ“ DeepSeeké”™è¯¯è§£æ - rate_limit
âœ“ Cerebrasé”™è¯¯è§£æ - network
âœ“ DashScopeé”™è¯¯è§£æ - authentication

æµ‹è¯• 3: ç¼“å­˜ç®¡ç†å™¨
âœ“ è®¾ç½®ç¼“å­˜
âœ“ è·å–ç¼“å­˜
âœ“ get_or_compute (é¦–æ¬¡è®¡ç®—)
âœ“ get_or_compute (ç¼“å­˜å‘½ä¸­)
âœ“ ç¼“å­˜ç»Ÿè®¡: å‘½ä¸­ç‡ 66.67%

æµ‹è¯• 4: ä¼šè¯çŠ¶æ€æŒä¹…åŒ–
âœ“ åˆ›å»ºä¼šè¯
âœ“ æ·»åŠ å¯¹è¯å†å²: 2 æ¡æ¶ˆæ¯
âœ“ æ›´æ–°æ¨¡å‹é…ç½®: openai/gpt-4o
âœ“ ä¿å­˜ä¼šè¯åˆ°ç£ç›˜
âœ“ åŠ è½½ä¼šè¯ (ä»ç¼“å­˜)
âœ“ å¯¼å‡ºä¼šè¯åˆ°æ–‡ä»¶
âœ“ ä¼šè¯åˆ—è¡¨: 2 ä¸ªä¼šè¯
âœ“ åˆ é™¤æµ‹è¯•ä¼šè¯

================================================================================
æµ‹è¯•å®Œæˆ! æ‰€æœ‰æµ‹è¯•é€šè¿‡ âœ“
================================================================================
```

---

## 8. å…¼å®¹æ€§è¯´æ˜

### 8.1 å‘åå…¼å®¹

- âœ… æ‰€æœ‰åŸæœ‰APIä¿æŒä¸å˜
- âœ… `api_service` (åŒæ­¥ç‰ˆæœ¬)ç»§ç»­å¯ç”¨
- âœ… ç°æœ‰ä»£ç æ— éœ€ä¿®æ”¹å³å¯è¿è¡Œ
- âœ… æ–°åŠŸèƒ½ä¸ºå¯é€‰å¢å¼º

### 8.2 æ¸è¿›å¼è¿ç§»

**é˜¶æ®µ1: æµ‹è¯•éªŒè¯ (å½“å‰)**

- è¿è¡Œæµ‹è¯•ç¡®ä¿æ–°åŠŸèƒ½æ­£å¸¸
- ä¿æŒç°æœ‰ä»£ç ä¸å˜

**é˜¶æ®µ2: å±€éƒ¨åº”ç”¨**

- éƒ¨åˆ†æ¥å£è¿ç§»åˆ°å¼‚æ­¥ç‰ˆæœ¬
- å¯ç”¨é”™è¯¯å¤„ç†å’Œç¼“å­˜

**é˜¶æ®µ3: å…¨é¢å‡çº§**

- æ‰€æœ‰APIè°ƒç”¨æ”¹ç”¨å¼‚æ­¥
- å¯ç”¨ä¼šè¯æŒä¹…åŒ–
- ä¼˜åŒ–æ·±åº¦æ€è€ƒæ€§èƒ½

---

## 9. æœªæ¥è§„åˆ’

### 9.1 çŸ­æœŸ (1-2ä¸ªæœˆ)

- [ ] Gradio UIé›†æˆå¼‚æ­¥API
- [ ] æ·»åŠ è¯·æ±‚è¿›åº¦æ¡
- [ ] å®ç°æµå¼å“åº”çš„å–æ¶ˆæŒ‰é’®
- [ ] ä¼šè¯åˆ—è¡¨UIç»„ä»¶

### 9.2 ä¸­æœŸ (3-6ä¸ªæœˆ)

- [ ] åˆ†å¸ƒå¼ç¼“å­˜ (Redis)
- [ ] ä¼šè¯æ•°æ®åº“å­˜å‚¨ (SQLite)
- [ ] è¯·æ±‚é˜Ÿåˆ—ç®¡ç†
- [ ] å®æ—¶æ€§èƒ½ç›‘æ§é¢æ¿

### 9.3 é•¿æœŸ (6-12ä¸ªæœˆ)

- [ ] å¤šç”¨æˆ·æ”¯æŒ
- [ ] WebSocketå®æ—¶é€šä¿¡
- [ ] äº‘ç«¯ä¼šè¯åŒæ­¥
- [ ] é«˜çº§åˆ†æå’ŒæŠ¥è¡¨

---

## 10. å¸¸è§é—®é¢˜ (FAQ)

### Q1: æ˜¯å¦éœ€è¦ä¿®æ”¹ç°æœ‰ä»£ç ?

**A:** ä¸éœ€è¦ã€‚æ‰€æœ‰æ–°åŠŸèƒ½éƒ½æ˜¯å¯é€‰çš„,ç°æœ‰ä»£ç ä¿æŒ100%å…¼å®¹ã€‚

---

### Q2: å¼‚æ­¥ç‰ˆæœ¬å’ŒåŒæ­¥ç‰ˆæœ¬æœ‰ä»€ä¹ˆåŒºåˆ«?

**A:**

| ç‰¹æ€§    | åŒæ­¥ç‰ˆæœ¬ (api_service) | å¼‚æ­¥ç‰ˆæœ¬ (async_api_service) |
|-------|--------------------|--------------------------|
| æ‰§è¡Œæ–¹å¼  | é˜»å¡å¼                | éé˜»å¡å¼                     |
| å¹¶å‘èƒ½åŠ›  | å•çº¿ç¨‹é¡ºåºæ‰§è¡Œ            | å¤šä»»åŠ¡å¹¶å‘æ‰§è¡Œ                  |
| è¯·æ±‚å–æ¶ˆ  | ä¸æ”¯æŒ                | æ”¯æŒ                       |
| è¶…æ—¶æ§åˆ¶  | ä¾èµ–åº•å±‚SDK            | ç²¾ç¡®æ§åˆ¶æ¯ä¸ªè¯·æ±‚                 |
| æ€§èƒ½    | åŸºå‡†                 | å¹¶å‘åœºæ™¯æå‡77%                |
| ä½¿ç”¨å¤æ‚åº¦ | ç®€å•                 | éœ€è¦async/await            |

---

### Q3: ç¼“å­˜ä¼šå ç”¨å¤šå°‘ç£ç›˜ç©ºé—´?

**A:**

- å“åº”ç¼“å­˜: ~50MB (500æ¡)
- ä¼šè¯ç¼“å­˜: ~20MB (100ä¸ªä¼šè¯)
- é…ç½®ç¼“å­˜: ~5MB (50ä¸ªé…ç½®)
- **æ€»è®¡: ~75MB** (å¯é…ç½®)

---

### Q4: å¦‚ä½•æ¸…ç©ºæ‰€æœ‰ç¼“å­˜?

**A:**

```python
from src.cache_manager import response_cache, session_cache, config_cache

response_cache.clear()
session_cache.clear()
config_cache.clear()
```

æˆ–è€…ç›´æ¥åˆ é™¤ç¼“å­˜ç›®å½•:

```bash
rm -rf .cache/
```

---

### Q5: é”™è¯¯å¤„ç†å™¨ä¼šå½±å“æ€§èƒ½å—?

**A:** å‡ ä¹æ— å½±å“ã€‚é”™è¯¯å¤„ç†åªåœ¨å¼‚å¸¸å‘ç”Ÿæ—¶è§¦å‘,æ­£å¸¸æµç¨‹æ— é¢å¤–å¼€é”€ã€‚

---

### Q6: å¦‚ä½•è‡ªå®šä¹‰ç¼“å­˜TTL?

**A:**

```python
from datetime import timedelta
from src.cache_manager import response_cache

# è®¾ç½®ç¼“å­˜,è‡ªå®šä¹‰è¿‡æœŸæ—¶é—´
response_cache.set(
    key="my_key",
    value="my_value",
    ttl=timedelta(hours=2)  # 2å°æ—¶è¿‡æœŸ
)
```

---

### Q7: æ·±åº¦æ€è€ƒçš„å¹¶è¡Œåº¦å¦‚ä½•é€‰æ‹©?

**A:**

- **è½»é‡æ¨¡å‹ (llama-3.3-70b)**: `max_parallel_tasks=3-4`
- **é‡å‹æ¨¡å‹ (gpt-4o)**: `max_parallel_tasks=2-3`
- **APIé™æµè¾ƒä¸¥**: `max_parallel_tasks=1-2`

**åŸåˆ™**: ä¸è¶…è¿‡APIæä¾›å•†çš„å¹¶å‘é™åˆ¶ã€‚

---

## 11. è´¡çŒ®æŒ‡å—

### 11.1 ä»£ç è§„èŒƒ

- éµå¾ª PEP 8
- ä½¿ç”¨ç±»å‹æ³¨è§£
- ç¼–å†™æ¸…æ™°çš„ docstring
- æ‰€æœ‰æ–°åŠŸèƒ½éœ€åŒ…å«å•å…ƒæµ‹è¯•

### 11.2 æäº¤æµç¨‹

1. Fork ä»“åº“
2. åˆ›å»ºåŠŸèƒ½åˆ†æ”¯ (`git checkout -b feature/AmazingFeature`)
3. æäº¤æ›´æ”¹ (`git commit -m 'Add some AmazingFeature'`)
4. æ¨é€åˆ°åˆ†æ”¯ (`git push origin feature/AmazingFeature`)
5. åˆ›å»º Pull Request

---

## 12. è®¸å¯è¯

MIT License

---

## 13. è”ç³»æ–¹å¼

- **é¡¹ç›®åœ°å€**: https://github.com/your-repo/SimpleLLMFront
- **é—®é¢˜åé¦ˆ**: https://github.com/your-repo/SimpleLLMFront/issues
- **æ–‡æ¡£**: https://github.com/your-repo/SimpleLLMFront/wiki

---

**æ›´æ–°æ—¥æœŸ**: 2025-12-04
**ç‰ˆæœ¬**: 2.0
**ä½œè€…**: Claude Code
