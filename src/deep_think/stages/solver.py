"""
è§£å†³é˜¶æ®µå¤„ç†å™¨
è´Ÿè´£é€ä¸ªåˆ†æå­ä»»åŠ¡
"""

from typing import Any, Dict, List

from ..core.interfaces import IPromptTemplate
from ..core.models import (
    Plan,
    StageContext,
    StageResult,
    Subtask,
    SubtaskResult,
    ThinkingStage,
)
from .base import BaseStageProcessor


class SolverStageProcessor(BaseStageProcessor):
    """è§£å†³é˜¶æ®µå¤„ç†å™¨"""

    def __init__(
        self,
        llm_service,
        json_parser,
        prompt_template: IPromptTemplate,
        verbose: bool = True,
        web_search_tool=None,
    ):
        """
        åˆå§‹åŒ–è§£å†³é˜¶æ®µå¤„ç†å™¨

        Args:
            llm_service: LLMæœåŠ¡å®ä¾‹
            json_parser: JSONè§£æå™¨
            prompt_template: æç¤ºæ¨¡æ¿
            verbose: æ˜¯å¦è¾“å‡ºè¯¦ç»†æ—¥å¿—
            web_search_tool: Webæœç´¢å·¥å…·å®ä¾‹ï¼ˆå¯é€‰ï¼‰
        """
        super().__init__(llm_service, json_parser, verbose)
        self.prompt_template = prompt_template
        self.web_search_tool = web_search_tool

    def get_stage(self) -> ThinkingStage:
        """è·å–é˜¶æ®µç±»å‹"""
        return ThinkingStage.SOLVE

    def execute(self, context: StageContext, **kwargs) -> StageResult:
        """æ‰§è¡Œè§£å†³é˜¶æ®µ"""
        subtask = kwargs.get("subtask")
        original_question = kwargs.get("original_question", "")
        previous_results = kwargs.get("previous_results", [])

        if not subtask:
            return self._create_error_result("å­ä»»åŠ¡ä¸èƒ½ä¸ºç©º")

        try:
            # æ„å»ºä¹‹å‰çš„ç»“è®ºä¸Šä¸‹æ–‡
            previous_conclusions = self._build_previous_conclusions(previous_results)

            # æ ¼å¼åŒ–æç¤ºè¯
            prompt = self.prompt_template.format(
                original_question=original_question,
                subtask_description=subtask.description,
                previous_conclusions=previous_conclusions,
            )

            # è°ƒç”¨LLM
            response = self._call_llm(prompt, context, self.get_stage())

            # è§£æå“åº”
            result_data = self._parse_json_response(response)

            # æ„å»ºSubtaskResultå¯¹è±¡
            result = self._build_subtask_result(subtask, result_data, response)

            # æ£€æŸ¥æ˜¯å¦éœ€è¦ç½‘ç»œæœç´¢
            if (
                result.needs_external_info
                and self.web_search_tool
                and self.web_search_tool.is_available()
            ):
                if self.verbose:
                    self.logger.info(f"[SOLVE] å­ä»»åŠ¡ {subtask.id} éœ€è¦å¤–éƒ¨ä¿¡æ¯ï¼Œæ‰§è¡Œç½‘ç»œæœç´¢...")
                result = self._enhance_with_web_search(result, original_question, context)

            if self.verbose:
                self.logger.info(f"[SOLVE] å®Œæˆå­ä»»åŠ¡ {subtask.id}: {subtask.description[:30]}...")

            return self._create_success_result(result, llm_calls=1)

        except Exception as e:
            # æ‰“å°åŸå§‹å“åº”æ–¹ä¾¿è°ƒè¯•
            if "response" in locals():
                # è¾“å‡ºå®Œæ•´å“åº”åˆ°æ—¥å¿—
                if len(response) > 0:
                    # é¢„è§ˆå‰1000å­—ç¬¦åˆ°WARNINGçº§åˆ«
                    self.logger.warning(
                        f"[SOLVE] å­ä»»åŠ¡ {subtask.id} æ‰§è¡Œå¤±è´¥ï¼Œå“åº”é•¿åº¦: {len(response)}, å‰1000å­—ç¬¦: {response[:1000]}"
                    )
                    # å®Œæ•´å“åº”åˆ°DEBUGçº§åˆ«
                    self.logger.debug(f"[SOLVE] å­ä»»åŠ¡ {subtask.id} å®Œæ•´åŸå§‹å“åº”: {response}")
                else:
                    self.logger.error(f"[SOLVE] å­ä»»åŠ¡ {subtask.id} æ‰§è¡Œå¤±è´¥ï¼Œå“åº”ä¸ºç©ºï¼")
            else:
                self.logger.error(f"[SOLVE] å­ä»»åŠ¡ {subtask.id} æ‰§è¡Œå¤±è´¥ï¼Œresponseå˜é‡æœªå®šä¹‰")

            self.logger.warning(f"[SOLVE] å­ä»»åŠ¡ {subtask.id} æ‰§è¡Œå¤±è´¥: {e}")
            # å®¹é”™: ä½¿ç”¨åŸå§‹å“åº”ä½œä¸ºåˆ†æç»“æœ
            result = self._create_fallback_result(
                subtask, response if "response" in locals() else str(e)
            )
            return self._create_success_result(result, llm_calls=1)

    def _build_previous_conclusions(self, previous_results: List[SubtaskResult]) -> str:
        """æ„å»ºä¹‹å‰çš„ç»“è®ºä¸Šä¸‹æ–‡"""
        if not previous_results:
            return "æš‚æ— "

        return "\n".join(
            [f"- å­ä»»åŠ¡{r.subtask_id}: {r.intermediate_conclusion}" for r in previous_results]
        )

    def _build_subtask_result(
        self, subtask: Subtask, result_data: Dict[str, Any], original_response: str
    ) -> SubtaskResult:
        """æ„å»ºSubtaskResultå¯¹è±¡"""
        return SubtaskResult(
            subtask_id=subtask.id,
            description=subtask.description,
            analysis=result_data.get("analysis", original_response),
            intermediate_conclusion=result_data.get("intermediate_conclusion", ""),
            confidence=float(result_data.get("confidence", 0.7)),
            limitations=result_data.get("limitations", []),
            needs_external_info=result_data.get("needs_external_info", False),
            suggested_tools=result_data.get("suggested_tools", []),
        )

    def _create_fallback_result(self, subtask: Subtask, response: str) -> SubtaskResult:
        """åˆ›å»ºå›é€€ç»“æœï¼ˆå®¹é”™å¤„ç†ï¼‰"""
        # ç¡®ä¿ response æ˜¯å­—ç¬¦ä¸²ä¸”ä¸ä¸ºç©º
        if not isinstance(response, str):
            response = str(response)

        conclusion = response.strip()
        if len(conclusion) > 200:
            conclusion = conclusion[:200] + "..."
        elif not conclusion:
            conclusion = "ï¼ˆå­ä»»åŠ¡æ‰§è¡Œå®Œæˆï¼Œä½†æœªèƒ½æå–ç»“è®ºï¼‰"

        return SubtaskResult(
            subtask_id=subtask.id,
            description=subtask.description,
            analysis=response,
            intermediate_conclusion=conclusion,
            confidence=0.6,
            limitations=["JSONè§£æå¤±è´¥ï¼Œä½¿ç”¨åŸå§‹å“åº”"],
        )

    def _enhance_with_web_search(
        self, result: SubtaskResult, original_question: str, context: StageContext
    ) -> SubtaskResult:
        """
        ä½¿ç”¨ç½‘ç»œæœç´¢å¢å¼ºå­ä»»åŠ¡ç»“æœ

        Args:
            result: åŸå§‹å­ä»»åŠ¡ç»“æœ
            original_question: åŸå§‹é—®é¢˜
            context: é˜¶æ®µä¸Šä¸‹æ–‡

        Returns:
            å¢å¼ºåçš„å­ä»»åŠ¡ç»“æœ
        """
        try:
            # æ„å»ºæœç´¢æŸ¥è¯¢
            search_queries = []

            # å¦‚æœæœ‰å»ºè®®çš„å·¥å…·å¹¶åŒ…å«"search"ï¼Œä½¿ç”¨å»ºè®®çš„æœç´¢å…³é”®è¯
            if result.suggested_tools and any(
                "search" in tool.lower() for tool in result.suggested_tools
            ):
                # ä»å­ä»»åŠ¡æè¿°ä¸­æå–å…³é”®è¯ä½œä¸ºæœç´¢æŸ¥è¯¢
                search_queries.append(result.description)
            else:
                # ä½¿ç”¨åŸå§‹é—®é¢˜å’Œå­ä»»åŠ¡æè¿°ç»„åˆ
                search_queries.append(f"{original_question} {result.description}")

            # æ‰§è¡Œæœç´¢å¹¶æ”¶é›†ç»“æœ
            all_search_results = []
            for query in search_queries[:1]:  # é™åˆ¶ä¸º1ä¸ªæŸ¥è¯¢é¿å…è¿‡åº¦æœç´¢
                if self.verbose:
                    self.logger.info(f"[SEARCH] æ‰§è¡Œæœç´¢: {query[:50]}...")

                search_results = self.web_search_tool.search_and_format(query, max_results=3)
                all_search_results.append(search_results)

            # å°†æœç´¢ç»“æœåˆå¹¶åˆ°åˆ†æä¸­
            enhanced_analysis = (
                result.analysis + "\n\n### ğŸŒ ç½‘ç»œæœç´¢ç»“æœ\n\n" + "\n\n".join(all_search_results)
            )

            # ä½¿ç”¨LLMé‡æ–°åˆ†æï¼Œæ•´åˆæœç´¢ç»“æœ
            integration_prompt = f"""
è¯·åŸºäºä»¥ä¸‹ä¿¡æ¯ï¼Œæ•´åˆç½‘ç»œæœç´¢ç»“æœåˆ°ä½ çš„åˆ†æä¸­ï¼š

**åŸå§‹é—®é¢˜:** {original_question}

**å­ä»»åŠ¡:** {result.description}

**åˆæ­¥åˆ†æ:**
{result.analysis}

**ç½‘ç»œæœç´¢ç»“æœ:**
{chr(10).join(all_search_results)}

è¯·æä¾›ä¸€ä¸ªæ•´åˆäº†æœç´¢ç»“æœçš„æ›´å®Œæ•´çš„åˆ†æå’Œç»“è®ºã€‚ä»¥JSONæ ¼å¼è¿”å›ï¼š
{{
    "enhanced_analysis": "æ•´åˆåçš„åˆ†æï¼ˆåŒ…å«æœç´¢ç»“æœçš„å…³é”®ä¿¡æ¯ï¼‰",
    "enhanced_conclusion": "æ›´æ–°åçš„ç»“è®º",
    "confidence": 0.0-1.0 çš„ç½®ä¿¡åº¦ï¼ˆè€ƒè™‘æœç´¢ç»“æœåï¼‰
}}
"""

            # è°ƒç”¨LLMæ•´åˆæœç´¢ç»“æœ
            integration_response = self._call_llm(integration_prompt, context, self.get_stage())
            integration_data = self._parse_json_response(integration_response)

            # æ›´æ–°ç»“æœ
            result.analysis = integration_data.get("enhanced_analysis", enhanced_analysis)
            result.intermediate_conclusion = integration_data.get(
                "enhanced_conclusion", result.intermediate_conclusion
            )
            result.confidence = float(integration_data.get("confidence", result.confidence))
            result.limitations.append("å·²æ•´åˆç½‘ç»œæœï¿½ï¿½ï¿½ç»“æœ")

            if self.verbose:
                self.logger.info(f"[SEARCH] æˆåŠŸæ•´åˆæœç´¢ç»“æœåˆ°å­ä»»åŠ¡ {result.subtask_id}")

        except Exception as e:
            self.logger.warning(f"[SEARCH] ç½‘ç»œæœç´¢å¢å¼ºå¤±è´¥: {e}")
            # å¤±è´¥æ—¶è¿”å›åŸå§‹ç»“æœ
            result.limitations.append(f"ç½‘ç»œæœç´¢å¤±è´¥: {e!s}")

        return result
