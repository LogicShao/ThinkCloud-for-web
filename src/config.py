"""
é…ç½®æ¨¡å— - ç®¡ç†åº”ç”¨é…ç½®ã€æä¾›å•†å’Œæ¨¡å‹åˆ—è¡¨
"""

import os
import socket

from dotenv import load_dotenv

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# æä¾›å•†é…ç½®
PROVIDER_CONFIG = {
    "cerebras": {
        "api_key": os.environ.get("CEREBRAS_API_KEY"),
        "base_url": "https://api.cerebras.ai",
        "enabled": True
    },
    "deepseek": {
        "api_key": os.environ.get("DEEPSEEK_API_KEY"),
        "base_url": "https://api.deepseek.com",
        "enabled": True
    },
    "openai": {
        "api_key": os.environ.get("OPENAI_API_KEY"),
        "base_url": "https://api.openai.com/v1",
        "enabled": True
    },
    "dashscope": {
        "api_key": os.environ.get("DASHSCOPE_API_KEY"),
        "base_url": "https://dashscope.aliyuncs.com/compatible-mode/v1",
        "enabled": True
    }
}

# æä¾›å•†æ”¯æŒçš„æ¨¡å‹æ˜ å°„
PROVIDER_MODELS = {
    "cerebras": [
        # Llamaç³»åˆ—
        "llama-3.3-70b",
        "llama-3.1-8b",
        "llama-3.1-70b",
        "llama-3.2-3b",
        "llama-3.2-1b",

        # å…¶ä»–æ¨¡å‹
        "qwen-3-235b-a22b-instruct-2507",
        "qwen-3-235b-a22b-thinking-2507",
        "zai-glm-4.6",
        "gpt-oss-120b",
        "qwen-3-32b"
    ],
    "deepseek": [
        "deepseek-chat",
        "deepseek-coder",
        "deepseek-reasoner"
    ],
    "openai": [
        "gpt-4o",
        "gpt-4o-mini",
        "gpt-4-turbo",
        "gpt-3.5-turbo"
    ],
    "dashscope": [
        "qwen-max",
        "qwen-plus",
        "qwen-turbo",
        "qwen-long",
        "qwen-vl-max",
        "qwen-vl-plus",
        "qwen-audio-turbo",
        "qwen2-7b-instruct",
        "qwen2-72b-instruct",
        "qwen2-1.5b-instruct",
        "qwen2-57b-a14b-instruct"
    ]
}

# é»˜è®¤æä¾›å•†å’Œæ¨¡å‹
DEFAULT_PROVIDER = "cerebras"
DEFAULT_MODEL = "qwen-3-235b-a22b-thinking-2507"

# æœåŠ¡å™¨é…ç½®
SERVER_HOST = "0.0.0.0"
SERVER_PORT = 7860

# ç•Œé¢é…ç½®
CHATBOT_HEIGHT = 500
MAX_INPUT_LINES = 5

# æä¾›å•†æ˜¾ç¤ºåç§°æ˜ å°„
PROVIDER_DISPLAY_NAMES = {
    "cerebras": "Cerebras",
    "deepseek": "DeepSeek",
    "openai": "OpenAI",
    "dashscope": "DashScope"
}


# è·å–æ‰€æœ‰æ”¯æŒçš„æ¨¡å‹
def get_supported_models():
    """è·å–æ‰€æœ‰å¯ç”¨çš„æä¾›å•†æ”¯æŒçš„æ¨¡å‹åˆ—è¡¨"""
    all_models = []
    for provider, config in PROVIDER_CONFIG.items():
        if config["enabled"] and config["api_key"]:
            all_models.extend(PROVIDER_MODELS.get(provider, []))
    return all_models


# è·å–å¸¦æä¾›å•†ä¿¡æ¯çš„æ¨¡å‹åˆ—è¡¨
def get_models_with_provider():
    """
    è·å–å¸¦æä¾›å•†ä¿¡æ¯çš„æ¨¡å‹åˆ—è¡¨ï¼Œæ ¼å¼ï¼š[(display_name, model_id), ...]

    Returns:
        list: [(æ˜¾ç¤ºåç§°, æ¨¡å‹ID), ...] ä¾‹å¦‚ï¼š[("ğŸ”¹ Cerebras | llama-3.3-70b", "llama-3.3-70b")]
    """
    models_with_provider = []

    # æŒ‰æä¾›å•†åˆ†ç»„
    for provider, config in PROVIDER_CONFIG.items():
        if config["enabled"] and config["api_key"]:
            provider_name = PROVIDER_DISPLAY_NAMES.get(provider, provider.capitalize())
            models = PROVIDER_MODELS.get(provider, [])

            for model in models:
                # æ ¼å¼ï¼šğŸ”¹ æä¾›å•† | æ¨¡å‹åç§°
                display_name = f"ğŸ”¹ {provider_name} | {model}"
                models_with_provider.append((display_name, model))

    return models_with_provider


# è·å–åˆ†ç»„çš„æ¨¡å‹å­—å…¸
def get_models_grouped_by_provider():
    """
    è·å–æŒ‰æä¾›å•†åˆ†ç»„çš„æ¨¡å‹å­—å…¸

    Returns:
        dict: {æä¾›å•†æ˜¾ç¤ºåç§°: [æ¨¡å‹åˆ—è¡¨]}
    """
    grouped_models = {}

    for provider, config in PROVIDER_CONFIG.items():
        if config["enabled"] and config["api_key"]:
            provider_name = PROVIDER_DISPLAY_NAMES.get(provider, provider.capitalize())
            models = PROVIDER_MODELS.get(provider, [])
            grouped_models[f"ğŸ“‚ {provider_name}"] = models

    return grouped_models


# ä»æ˜¾ç¤ºåç§°æå–æ¨¡å‹ID
def extract_model_id(display_name):
    """
    ä»æ˜¾ç¤ºåç§°ä¸­æå–å®é™…çš„æ¨¡å‹ID

    Args:
        display_name: æ˜¾ç¤ºåç§°ï¼Œä¾‹å¦‚ "ğŸ”¹ Cerebras | llama-3.3-70b"

    Returns:
        str: æ¨¡å‹IDï¼Œä¾‹å¦‚ "llama-3.3-70b"
    """
    if " | " in display_name:
        return display_name.split(" | ")[-1]
    return display_name


# è·å–æ¨¡å‹çš„æ˜¾ç¤ºåç§°
def get_model_display_name(model_id):
    """
    è·å–æ¨¡å‹çš„æ˜¾ç¤ºåç§°ï¼ˆå¸¦æä¾›å•†ä¿¡æ¯ï¼‰

    Args:
        model_id: æ¨¡å‹ID

    Returns:
        str: æ˜¾ç¤ºåç§°ï¼Œä¾‹å¦‚ "ğŸ”¹ Cerebras | llama-3.3-70b"
    """
    provider = get_model_provider(model_id)
    if provider:
        provider_name = PROVIDER_DISPLAY_NAMES.get(provider, provider.capitalize())
        return f"ğŸ”¹ {provider_name} | {model_id}"
    return model_id


# è·å–å¯ç”¨çš„æä¾›å•†åˆ—è¡¨
def get_enabled_providers():
    """è·å–å·²é…ç½®ä¸”å¯ç”¨çš„æä¾›å•†åˆ—è¡¨"""
    enabled_providers = []
    for provider, config in PROVIDER_CONFIG.items():
        if config["enabled"] and config["api_key"]:
            enabled_providers.append(provider)
    return enabled_providers


# æ£€æŸ¥APIå¯†é’¥é…ç½®
def check_api_key(provider=None):
    """
    æ£€æŸ¥APIå¯†é’¥æ˜¯å¦é…ç½®

    Args:
        provider: æŒ‡å®šæä¾›å•†ï¼ŒNoneè¡¨ç¤ºæ£€æŸ¥æ‰€æœ‰æä¾›å•†

    Returns:
        bool: æ˜¯å¦è‡³å°‘æœ‰ä¸€ä¸ªæä¾›å•†é…ç½®äº†APIå¯†é’¥
    """
    if provider:
        config = PROVIDER_CONFIG.get(provider, {})
        if not config.get("api_key"):
            print(f"è­¦å‘Š: {provider.upper()}_API_KEY ç¯å¢ƒå˜é‡æœªè®¾ç½®")
            print(f"è¯·åˆ›å»º.envæ–‡ä»¶å¹¶æ·»åŠ : {provider.upper()}_API_KEY=your_api_key_here")
            return False
        return True

    # æ£€æŸ¥æ‰€æœ‰æä¾›å•†
    has_valid_provider = False
    for provider, config in PROVIDER_CONFIG.items():
        if config["enabled"] and config["api_key"]:
            has_valid_provider = True
            break

    if not has_valid_provider:
        print("è­¦å‘Š: æ²¡æœ‰é…ç½®ä»»ä½•æœ‰æ•ˆçš„APIå¯†é’¥")
        print("è¯·è‡³å°‘é…ç½®ä»¥ä¸‹ç¯å¢ƒå˜é‡ä¹‹ä¸€:")
        for provider in PROVIDER_CONFIG:
            print(f"  - {provider.upper()}_API_KEY")
        return False

    return True


# è·å–æä¾›å•†é…ç½®
def get_provider_config(provider):
    """è·å–æŒ‡å®šæä¾›å•†çš„é…ç½®"""
    return PROVIDER_CONFIG.get(provider, {})


# è·å–æ¨¡å‹å¯¹åº”çš„æä¾›å•†
def get_model_provider(model):
    """æ ¹æ®æ¨¡å‹åç§°è·å–å¯¹åº”çš„æä¾›å•†"""
    for provider, models in PROVIDER_MODELS.items():
        if model in models:
            return provider
    return None


# ç«¯å£ç®¡ç†å·¥å…·å‡½æ•°
def is_port_available(port, host="0.0.0.0"):
    """
    æ£€æŸ¥æŒ‡å®šç«¯å£æ˜¯å¦å¯ç”¨

    Args:
        port: è¦æ£€æŸ¥çš„ç«¯å£å·
        host: ä¸»æœºåœ°å€ï¼Œé»˜è®¤ä¸º 0.0.0.0

    Returns:
        bool: ç«¯å£å¯ç”¨è¿”å›Trueï¼Œå¦åˆ™è¿”å›False
    """
    try:
        # åˆ›å»ºsocketå¯¹è±¡
        with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as sock:
            # å°è¯•ç»‘å®šç«¯å£ï¼ˆä¸è®¾ç½®SO_REUSEADDRï¼Œç¡®ä¿æ£€æµ‹å‡†ç¡®ï¼‰
            sock.bind((host, port))
            return True
    except OSError:
        # ç«¯å£è¢«å ç”¨æˆ–å…¶ä»–é”™è¯¯
        return False


def find_available_port(start_port=7860, max_attempts=100, host="0.0.0.0"):
    """
    è‡ªåŠ¨æŸ¥æ‰¾å¯ç”¨ç«¯å£

    ä»èµ·å§‹ç«¯å£å¼€å§‹ï¼Œä¾æ¬¡å°è¯•æ‰¾åˆ°ç¬¬ä¸€ä¸ªå¯ç”¨çš„ç«¯å£

    Args:
        start_port: èµ·å§‹ç«¯å£å·ï¼Œé»˜è®¤ä¸º7860
        max_attempts: æœ€å¤§å°è¯•æ¬¡æ•°ï¼Œé»˜è®¤ä¸º100
        host: ä¸»æœºåœ°å€ï¼Œé»˜è®¤ä¸º 0.0.0.0

    Returns:
        int: æ‰¾åˆ°çš„å¯ç”¨ç«¯å£å·ï¼Œå¦‚æœæ²¡æœ‰æ‰¾åˆ°è¿”å›None
    """
    for port in range(start_port, start_port + max_attempts):
        if is_port_available(port, host):
            return port

    print(f"[WARN] è­¦å‘Š: åœ¨ {start_port}-{start_port + max_attempts - 1} èŒƒå›´å†…æœªæ‰¾åˆ°å¯ç”¨ç«¯å£")
    return None


def get_server_port(preferred_port=SERVER_PORT, host=SERVER_HOST):
    """
    è·å–æœåŠ¡å™¨ç«¯å£ï¼Œä¼˜å…ˆä½¿ç”¨é¦–é€‰ç«¯å£ï¼Œå¦‚æœè¢«å ç”¨åˆ™è‡ªåŠ¨æŸ¥æ‰¾å¯ç”¨ç«¯å£

    Args:
        preferred_port: é¦–é€‰ç«¯å£å·ï¼Œé»˜è®¤ä¸ºé…ç½®ä¸­çš„SERVER_PORT
        host: ä¸»æœºåœ°å€ï¼Œé»˜è®¤ä¸ºé…ç½®ä¸­çš„SERVER_HOST

    Returns:
        int: å¯ç”¨çš„ç«¯å£å·
    """
    # é¦–å…ˆæ£€æŸ¥é¦–é€‰ç«¯å£
    if is_port_available(preferred_port, host):
        print(f"[OK] ä½¿ç”¨ç«¯å£: {preferred_port}")
        return preferred_port

    # é¦–é€‰ç«¯å£è¢«å ç”¨ï¼ŒæŸ¥æ‰¾å¯ç”¨ç«¯å£
    print(f"[WARN] ç«¯å£ {preferred_port} å·²è¢«å ç”¨ï¼Œæ­£åœ¨æŸ¥æ‰¾å¯ç”¨ç«¯å£...")
    available_port = find_available_port(preferred_port + 1, max_attempts=100, host=host)

    if available_port:
        print(f"[OK] æ‰¾åˆ°å¯ç”¨ç«¯å£: {available_port}")
        return available_port
    else:
        # å®åœ¨æ‰¾ä¸åˆ°ï¼Œè¿”å›Noneè®©ç³»ç»Ÿéšæœºåˆ†é…
        print("[WARN] æœªæ‰¾åˆ°å¯ç”¨ç«¯å£ï¼Œå°†ä½¿ç”¨ç³»ç»Ÿéšæœºåˆ†é…çš„ç«¯å£")
        return None
