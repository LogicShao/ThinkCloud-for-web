"""
UIå¸ƒå±€æ„å»ºå™¨ - çº¯UIåˆ›å»ºï¼Œä¸æ¶‰åŠä¸šåŠ¡é€»è¾‘
éµå¾ªå•ä¸€èŒè´£åŸåˆ™ï¼Œåªè´Ÿè´£åˆ›å»ºå’Œå¸ƒå±€Gradioç•Œé¢ç»„ä»¶
"""

import gradio as gr

from src.config import (
    CHATBOT_HEIGHT,
    DEFAULT_MODEL,
    MAX_INPUT_LINES,
    MODEL_PARAMETERS,
)


class UIComposer:
    """UIå¸ƒå±€æ„å»ºç±»"""

    def __init__(self):
        pass

    def create_interface(
        self,
        header_markdown_fn,
        status_html_fn,
        event_handlers,
        update_models_fn,
        update_status_fn,
    ):
        """
        åˆ›å»ºGradioç•Œé¢

        Args:
            header_markdown_fn: å¤´éƒ¨Markdownå›è°ƒå‡½æ•°
            status_html_fn: çŠ¶æ€HTMLç”Ÿæˆå›è°ƒå‡½æ•°
            event_handlers: äº‹ä»¶å¤„ç†å™¨å®ä¾‹
            update_models_fn: æ›´æ–°æ¨¡å‹åˆ—è¡¨å‡½æ•°
            update_status_fn: æ›´æ–°çŠ¶æ€ä¿¡æ¯å‡½æ•°

        Returns:
            gradio.Blocks: Gradioç•Œé¢å®ä¾‹
        """
        with gr.Blocks(title="ThinkCloud for Web - AI æ™ºèƒ½å¯¹è¯") as demo:
            # æ ‡é¢˜å’Œæè¿°
            gr.Markdown(header_markdown_fn())

            # ä¸»è¦å†…å®¹åŒºåŸŸ
            with gr.Row(equal_height=True):
                # å·¦ä¾§æ§åˆ¶é¢æ¿
                with gr.Column(scale=1, min_width=250):
                    gr.Markdown("### æ§åˆ¶ä¸­å¿ƒ")

                    # è·å–åˆ†ç»„çš„æ¨¡å‹æ•°æ®
                    from src.config import PROVIDER_DISPLAY_NAMES, get_enabled_providers

                    enabled_providers = get_enabled_providers()
                    provider_choices = [
                        PROVIDER_DISPLAY_NAMES.get(p, p.capitalize()) for p in enabled_providers
                    ]

                    # è·å–é»˜è®¤æä¾›å•†å’Œæ¨¡å‹
                    from src.config import get_model_provider

                    default_provider_id = get_model_provider(DEFAULT_MODEL)
                    default_provider_name = (
                        PROVIDER_DISPLAY_NAMES.get(
                            default_provider_id, default_provider_id.capitalize()
                        )
                        if default_provider_id
                        else provider_choices[0]
                    )

                    # æä¾›å•†å’Œæ¨¡å‹é€‰æ‹©ï¼ˆæ°´å¹³æ’åˆ—ï¼‰
                    provider_dropdown = gr.Dropdown(
                        choices=provider_choices,
                        value=default_provider_name,
                        label="æä¾›å•†",
                        info="AIæœåŠ¡æä¾›å•†",
                        interactive=True,
                    )

                    from src.config import PROVIDER_MODELS

                    default_models = (
                        PROVIDER_MODELS.get(default_provider_id, []) if default_provider_id else []
                    )

                    model_dropdown = gr.Dropdown(
                        choices=default_models,
                        value=DEFAULT_MODEL
                        if DEFAULT_MODEL in default_models
                        else (default_models[0] if default_models else ""),
                        label="æ¨¡å‹",
                        info="AIæ¨¡å‹",
                        interactive=True,
                    )

                    # ç³»ç»ŸçŠ¶æ€
                    gr.Markdown("### ç³»ç»ŸçŠ¶æ€")
                    status_html = gr.HTML(value=status_html_fn())

                    gr.Markdown("### æ¨¡å‹å‚æ•°")

                    # æ§åˆ¶é€‰é¡¹ï¼ˆæ°´å¹³æ’åˆ—ï¼‰
                    with gr.Row():
                        enable_streaming = gr.Checkbox(
                            label="æµå¼è¾“å‡º", value=True, scale=1
                        )
                        deep_think_enabled = gr.Checkbox(
                            label="æ·±åº¦æ€è€ƒ", value=False, scale=1
                        )

                    # ç³»ç»Ÿæç¤ºè¯
                    system_instruction = gr.Textbox(
                        label="ç³»ç»Ÿæç¤ºè¯",
                        placeholder="è®¾ç½®AIè§’è‰²å’Œè¡Œä¸º",
                        value="",
                        lines=2,
                        info="ç•™ç©ºä½¿ç”¨é»˜è®¤å€¼",
                    )

                    # ä¸»è¦å‚æ•°
                    temperature = gr.Slider(
                        minimum=MODEL_PARAMETERS["temperature"]["min"],
                        maximum=MODEL_PARAMETERS["temperature"]["max"],
                        value=MODEL_PARAMETERS["temperature"]["default"],
                        step=MODEL_PARAMETERS["temperature"]["step"],
                        label="æ¸©åº¦",
                        info="éšæœºæ€§æ§åˆ¶",
                    )

                    # é«˜çº§å‚æ•°
                    with gr.Accordion("é«˜çº§å‚æ•°", open=False):
                        top_p = gr.Slider(
                            minimum=MODEL_PARAMETERS["top_p"]["min"],
                            maximum=MODEL_PARAMETERS["top_p"]["max"],
                            value=MODEL_PARAMETERS["top_p"]["default"],
                            step=MODEL_PARAMETERS["top_p"]["step"],
                            label="Top P",
                            info="è¯æ±‡èŒƒå›´æ§åˆ¶",
                        )

                        max_tokens = gr.Slider(
                            minimum=MODEL_PARAMETERS["max_tokens"]["min"],
                            maximum=MODEL_PARAMETERS["max_tokens"]["max"],
                            value=MODEL_PARAMETERS["max_tokens"]["default"],
                            step=MODEL_PARAMETERS["max_tokens"]["step"],
                            label="æœ€å¤§é•¿åº¦",
                            info="Tokenä¸Šé™",
                        )

                        frequency_penalty = gr.Slider(
                            minimum=MODEL_PARAMETERS["frequency_penalty"]["min"],
                            maximum=MODEL_PARAMETERS["frequency_penalty"]["max"],
                            value=MODEL_PARAMETERS["frequency_penalty"]["default"],
                            step=MODEL_PARAMETERS["frequency_penalty"]["step"],
                            label="é¢‘ç‡æƒ©ç½š",
                            info="å‡å°‘é‡å¤è¯",
                        )

                        presence_penalty = gr.Slider(
                            minimum=MODEL_PARAMETERS["presence_penalty"]["min"],
                            maximum=MODEL_PARAMETERS["presence_penalty"]["max"],
                            value=MODEL_PARAMETERS["presence_penalty"]["default"],
                            step=MODEL_PARAMETERS["presence_penalty"]["step"],
                            label="å­˜åœ¨æƒ©ç½š",
                            info="å¢åŠ å¤šæ ·æ€§",
                        )

                    # æ·±åº¦æ€è€ƒé€‰é¡¹
                    with gr.Accordion("æ·±åº¦æ€è€ƒé€‰é¡¹", open=False):
                        enable_review = gr.Checkbox(
                            label="è‡ªæˆ‘å®¡æŸ¥", value=True, info="è´¨é‡å®¡æŸ¥"
                        )
                        enable_web_search = gr.Checkbox(
                            label="ç½‘ç»œæœç´¢", value=False, info="æœç´¢å¤–éƒ¨ä¿¡æ¯"
                        )
                        show_thinking_process = gr.Checkbox(
                            label="æ˜¾ç¤ºè¿‡ç¨‹", value=True, info="å±•ç¤ºæ¨ç†æ­¥éª¤"
                        )
                        max_subtasks = gr.Slider(
                            minimum=3,
                            maximum=8,
                            value=6,
                            step=1,
                            label="å­ä»»åŠ¡æ•°",
                            info="é—®é¢˜æ‹†è§£æ•°é‡",
                        )

                    gr.Markdown(
                        """
                    ğŸ’¡ **åŠŸèƒ½æç¤º**

                    â€¢ æ”¯æŒ Markdown æ ¼å¼
                    â€¢ æ”¯æŒä»£ç é«˜äº®
                    â€¢ æ”¯æŒå¤šè½®å¯¹è¯
                    â€¢ å¯éšæ—¶åˆ‡LLMæ¨¡å‹
                    â€¢ ğŸ§  æ·±åº¦æ€è€ƒæ¨¡å¼å¯è§£å†³å¤æ‚é—®é¢˜
                    â€¢ ğŸŒ ç½‘ç»œæœç´¢åŠŸèƒ½å¯è·å–æœ€æ–°ä¿¡æ¯
                    """
                    )

                # å³ä¾§èŠå¤©åŒºåŸŸ
                with gr.Column(scale=3, min_width=600):
                    # èŠå¤©ç•Œé¢
                    chatbot = gr.Chatbot(
                        label="å¯¹è¯",
                        height=CHATBOT_HEIGHT,
                        latex_delimiters=[],
                        line_breaks=True,
                        render_markdown=True,
                        buttons=["copy_all"],
                    )

            # è¾“å…¥åŒºåŸŸ
            with gr.Row():
                with gr.Column(scale=1, min_width=250):
                    pass

                with gr.Column(scale=3, min_width=600), gr.Row():
                    msg = gr.Textbox(
                        label="",
                        placeholder="è¾“å…¥é—®é¢˜...",
                        scale=5,
                        max_lines=MAX_INPUT_LINES,
                        container=False,
                    )
                    submit_btn = gr.Button(
                        "å‘é€", variant="primary", scale=1, size="sm", min_width=60
                    )

            # æ§åˆ¶æŒ‰é’®åŒºåŸŸ
            with gr.Row():
                with gr.Column(scale=1, min_width=250):
                    pass

                with gr.Column(scale=3, min_width=600), gr.Row():
                    clear_btn = gr.Button("æ¸…é™¤", variant="secondary", size="sm", scale=1)
                    export_btn = gr.Button("å¯¼å‡º", variant="secondary", size="sm", scale=1)
                    gr.Markdown("ThinkCloud")

            # ç»‘å®šäº‹ä»¶ï¼ˆé€šè¿‡äº‹ä»¶å¤„ç†å™¨ï¼‰
            event_handlers.setup_all_events(
                demo,
                msg,
                chatbot,
                provider_dropdown,
                model_dropdown,
                submit_btn,
                clear_btn,
                export_btn,
                status_html,
                enable_streaming,
                system_instruction,
                temperature,
                top_p,
                max_tokens,
                frequency_penalty,
                presence_penalty,
                deep_think_enabled,
                enable_review,
                enable_web_search,
                show_thinking_process,
                max_subtasks,
                update_models_fn,
                update_status_fn,
            )

            # é¡µé¢åŠ è½½æ—¶æ›´æ–°çŠ¶æ€
            demo.load(update_status_fn, None, status_html)

        return demo

    def _create_input_section(self):
        """åˆ›å»ºè¾“å…¥åŒºåŸŸç»„ä»¶"""
        pass
