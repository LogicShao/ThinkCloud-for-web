"""
å¤šæä¾›å•† LLM å®¢æˆ·ç«¯ - ä¸»åº”ç”¨æ–‡ä»¶
é‡æ„ç‰ˆæœ¬ï¼Œæ”¯æŒå¤šä¸ªAIæä¾›å•†å’Œæ›´å¥½çš„æ¨¡å—åŒ–
"""

import gradio as gr

from src.api_service import api_service
from src.chat_manager import ChatManager, MessageProcessor
from src.config import (
    DEFAULT_MODEL, SERVER_HOST, SERVER_PORT,
    CHATBOT_HEIGHT, MAX_INPUT_LINES, check_api_key, get_server_port
)


class LLMClient:
    """LLMå®¢æˆ·ç«¯ä¸»ç±»"""

    def __init__(self):
        self.chat_manager = ChatManager()
        self.message_processor = MessageProcessor()

    def create_interface(self):
        """åˆ›å»ºGradioç•Œé¢"""
        with gr.Blocks(title="å¤šæä¾›å•† LLM å®¢æˆ·ç«¯") as demo:
            # æ ‡é¢˜å’Œæè¿°
            gr.Markdown(self._get_header_markdown())

            # ä¸»è¦å†…å®¹åŒºåŸŸ
            with gr.Row(equal_height=True):
                # å·¦ä¾§æ§åˆ¶é¢æ¿
                with gr.Column(scale=1, min_width=280):
                    gr.Markdown("### ğŸ›ï¸ æ§åˆ¶ä¸­å¿ƒ")

                    # è·å–åˆ†ç»„çš„æ¨¡å‹æ•°æ®
                    from src.config import get_enabled_providers, PROVIDER_DISPLAY_NAMES

                    enabled_providers = get_enabled_providers()
                    provider_choices = [PROVIDER_DISPLAY_NAMES.get(p, p.capitalize()) for p in enabled_providers]

                    # è·å–é»˜è®¤æä¾›å•†å’Œæ¨¡å‹
                    from src.config import get_model_provider
                    default_provider_id = get_model_provider(DEFAULT_MODEL)
                    default_provider_name = PROVIDER_DISPLAY_NAMES.get(default_provider_id,
                                                                       default_provider_id.capitalize()) if default_provider_id else \
                    provider_choices[0]

                    # ç¬¬ä¸€çº§ï¼šé€‰æ‹©æä¾›å•†
                    provider_dropdown = gr.Dropdown(
                        choices=provider_choices,
                        value=default_provider_name,
                        label="ğŸ¢ é€‰æ‹©æä¾›å•†",
                        info="é€‰æ‹©AIæœåŠ¡æä¾›å•†",
                        interactive=True
                    )

                    # ç¬¬äºŒçº§ï¼šé€‰æ‹©æ¨¡å‹
                    from src.config import PROVIDER_MODELS
                    # è·å–é»˜è®¤æä¾›å•†çš„æ¨¡å‹åˆ—è¡¨
                    default_models = PROVIDER_MODELS.get(default_provider_id, []) if default_provider_id else []

                    model_dropdown = gr.Dropdown(
                        choices=default_models,
                        value=DEFAULT_MODEL if DEFAULT_MODEL in default_models else (
                            default_models[0] if default_models else ""),
                        label="ğŸ¤– é€‰æ‹©æ¨¡å‹",
                        info="é€‰æ‹©å…·ä½“çš„AIæ¨¡å‹",
                        interactive=True
                    )

                    # ç³»ç»ŸçŠ¶æ€æ˜¾ç¤ºï¼ˆä¼˜åŒ–ç‰ˆï¼‰
                    gr.Markdown("### ğŸ“Š ç³»ç»ŸçŠ¶æ€")
                    status_html = gr.HTML(value=self._get_status_html())

                    gr.Markdown("""
                    ğŸ’¡ **åŠŸèƒ½æç¤º**

                    â€¢ æ”¯æŒ Markdown æ ¼å¼
                    â€¢ æ”¯æŒä»£ç é«˜äº®
                    â€¢ æ”¯æŒå¤šè½®å¯¹è¯
                    â€¢ å¯éšæ—¶åˆ‡æ¢æ¨¡å‹
                    """)

                # å³ä¾§èŠå¤©åŒºåŸŸ
                with gr.Column(scale=3, min_width=600):
                    # èŠå¤©ç•Œé¢
                    chatbot = gr.Chatbot(
                        label="ğŸ’¬ å¯¹è¯ç•Œé¢",
                        height=CHATBOT_HEIGHT,
                        type="messages",
                        show_copy_button=True
                    )

            # è¾“å…¥åŒºåŸŸï¼ˆä¸ä¸Šæ–¹å¯¹é½ï¼‰
            with gr.Row():
                with gr.Column(scale=1, min_width=280):
                    pass  # å ä½ï¼Œä¸å·¦ä¾§æ§åˆ¶é¢æ¿å¯¹é½

                with gr.Column(scale=3, min_width=600):
                    with gr.Row():
                        msg = gr.Textbox(
                            label="âœï¸ è¾“å…¥æ¶ˆæ¯",
                            placeholder="ğŸ’­ è¯·è¾“å…¥æ‚¨çš„é—®é¢˜...",
                            scale=5,
                            max_lines=MAX_INPUT_LINES,
                            show_copy_button=False,
                            container=False
                        )
                        submit_btn = gr.Button(
                            "ğŸš€ å‘é€",
                            variant="primary",
                            scale=1,
                            size="sm",
                            min_width=80
                        )

            # æ§åˆ¶æŒ‰é’®åŒºåŸŸï¼ˆä¸ä¸Šæ–¹å¯¹é½ï¼‰
            with gr.Row():
                with gr.Column(scale=1, min_width=280):
                    pass  # å ä½

                with gr.Column(scale=3, min_width=600):
                    with gr.Row():
                        clear_btn = gr.Button("ğŸ—‘ï¸ æ¸…é™¤å¯¹è¯", variant="secondary", size="sm", scale=1)
                        export_btn = gr.Button("ğŸ“¥ å¯¼å‡ºå¯¹è¯", variant="secondary", size="sm", scale=1)
                        gr.Markdown("*Powered by Multi-Provider LLM*")

            # ç»‘å®šäº‹ä»¶
            self._setup_event_handlers(
                demo, msg, chatbot, provider_dropdown, model_dropdown,
                submit_btn, clear_btn, export_btn, status_html
            )

        return demo

    def _get_header_markdown(self):
        """è·å–å¤´éƒ¨Markdownå†…å®¹"""
        return """
        # ğŸš€ å¤šæä¾›å•† AI èŠå¤©å®¢æˆ·ç«¯

        æ¢ç´¢ä¸‹ä¸€ä»£ AI å¯¹è¯ä½“éªŒ - æ”¯æŒå¤šä¸ªé¢†å…ˆçš„å¤§è¯­è¨€æ¨¡å‹æä¾›å•†

        ---

        **ğŸ¤– æ”¯æŒçš„æä¾›å•†:** Cerebras â€¢ DeepSeek â€¢ OpenAI â€¢ DashScope

        **âš¡ æ¨¡å‹ç³»åˆ—:** Llama â€¢ Qwen â€¢ DeepSeek â€¢ GPT

        **âœ¨ ç‰¹æ€§:** å¿«é€Ÿå“åº” â€¢ æ™ºèƒ½åˆ‡æ¢ â€¢ å†å²è®°å½•
        """

    def _get_initial_status(self):
        """è·å–åˆå§‹çŠ¶æ€ä¿¡æ¯"""
        return api_service.get_provider_status()

    def _get_status_html(self):
        """ç”ŸæˆHTMLæ ¼å¼çš„ç³»ç»ŸçŠ¶æ€æ˜¾ç¤º"""
        from src.config import get_enabled_providers, PROVIDER_DISPLAY_NAMES

        enabled_providers = get_enabled_providers()
        history_count = self.chat_manager.get_history_length()

        # æ„å»ºæä¾›å•†åˆ—è¡¨
        provider_list = []
        for provider in enabled_providers:
            provider_name = PROVIDER_DISPLAY_NAMES.get(provider, provider.capitalize())
            provider_list.append(f'âœ“ {provider_name}')

        providers_text = ', '.join(provider_list)

        # æ„å»ºçŠ¶æ€HTML
        status_html = f'''
        <div>
            <p><strong>å¯ç”¨æä¾›å•†ï¼š</strong>{providers_text}</p>
            <p><strong>å¯¹è¯è½®æ•°ï¼š</strong>{history_count}</p>
        </div>
        '''

        return status_html

    def _setup_event_handlers(
            self, demo, msg, chatbot, provider_dropdown, model_dropdown,
            submit_btn, clear_btn, export_btn, status_html
    ):
        """è®¾ç½®äº‹ä»¶å¤„ç†å™¨"""

        def update_models(provider_name):
            """å½“æä¾›å•†å˜æ›´æ—¶æ›´æ–°æ¨¡å‹åˆ—è¡¨"""
            from src.config import PROVIDER_MODELS, PROVIDER_DISPLAY_NAMES

            # ä»æ˜¾ç¤ºåç§°è·å–æä¾›å•†ID
            provider_id = None
            for pid, display_name in PROVIDER_DISPLAY_NAMES.items():
                if display_name == provider_name:
                    provider_id = pid
                    break

            # è·å–è¯¥æä¾›å•†çš„æ¨¡å‹åˆ—è¡¨
            models = PROVIDER_MODELS.get(provider_id, []) if provider_id else []

            # è¿”å›æ›´æ–°åçš„ä¸‹æ‹‰æ¡†é…ç½®
            return gr.update(choices=models, value=models[0] if models else "")

        def user_message(user_msg, history, model):
            """å¤„ç†ç”¨æˆ·æ¶ˆæ¯"""
            if not user_msg.strip():
                return "", history

            # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯åˆ°å†å²
            self.chat_manager.add_message("user", user_msg)

            # æ›´æ–°Gradioç•Œé¢
            new_history = history + [{"role": "user", "content": user_msg}]
            return "", new_history

        def bot_message(history, model):
            """è·å–æœºå™¨äººå›å¤"""
            if not history:
                return history

            # æ„å»ºAPIæ¶ˆæ¯ - ç›´æ¥ä½¿ç”¨Gradioçš„historyæ ¼å¼
            api_messages = []
            for msg in history:
                if msg["role"] in ["user", "assistant"]:
                    api_messages.append({
                        "role": msg["role"],
                        "content": msg["content"]
                    })

            # è°ƒç”¨API
            response = api_service.chat_completion(api_messages, model)

            # æ·»åŠ åŠ©æ‰‹å›å¤åˆ°å†å²
            self.chat_manager.add_message("assistant", response)

            # æ›´æ–°Gradioç•Œé¢
            history.append({"role": "assistant", "content": response})
            return history

        def clear_conversation():
            """æ¸…é™¤å¯¹è¯"""
            self.chat_manager.clear_history()
            return [], self._get_status_html()

        def export_conversation():
            """å¯¼å‡ºå¯¹è¯"""
            if not self.chat_manager.history:
                return self._get_status_html()

            export_text = "å¤šæä¾›å•† LLM å¯¹è¯è®°å½•\n" + "=" * 50 + "\n"
            for msg in self.chat_manager.history:
                role = "ç”¨æˆ·" if msg["role"] == "user" else "åŠ©æ‰‹"
                export_text += f"{role}: {msg['content']}\n\n"

            return export_text

        def update_status():
            """æ›´æ–°çŠ¶æ€ä¿¡æ¯ï¼ˆHTMLæ ¼å¼ï¼‰"""
            return self._get_status_html()

        # æä¾›å•†å˜æ›´äº‹ä»¶ - æ›´æ–°æ¨¡å‹åˆ—è¡¨
        provider_dropdown.change(
            update_models,
            inputs=[provider_dropdown],
            outputs=[model_dropdown]
        )

        # ç»‘å®šäº‹ä»¶
        msg.submit(
            user_message,
            [msg, chatbot, model_dropdown],
            [msg, chatbot],
            queue=False
        ).then(
            bot_message,
            [chatbot, model_dropdown],
            [chatbot]
        ).then(
            update_status,
            None,
            [status_html]
        )

        submit_btn.click(
            user_message,
            [msg, chatbot, model_dropdown],
            [msg, chatbot],
            queue=False
        ).then(
            bot_message,
            [chatbot, model_dropdown],
            [chatbot]
        ).then(
            update_status,
            None,
            [status_html]
        )

        clear_btn.click(
            clear_conversation,
            None,
            [chatbot, status_html],
            queue=False
        )

        export_btn.click(
            export_conversation,
            None,
            [status_html],
            queue=False
        )

        # é¡µé¢åŠ è½½æ—¶æ›´æ–°çŠ¶æ€
        demo.load(update_status, None, status_html)


def main():
    """ä¸»å‡½æ•°"""
    print("[START] å¯åŠ¨ å¤šæä¾›å•† LLM å®¢æˆ·ç«¯...")

    # æ£€æŸ¥APIé…ç½®
    if not check_api_key():
        print("\n[WARN] è¯·å…ˆé…ç½®è‡³å°‘ä¸€ä¸ªAPIå¯†é’¥ç¯å¢ƒå˜é‡")
        print("   åˆ›å»º.envæ–‡ä»¶å¹¶æ·»åŠ ä»¥ä¸‹å˜é‡ä¹‹ä¸€:")
        print("   - CEREBRAS_API_KEY=your_api_key_here")
        print("   - DEEPSEEK_API_KEY=your_api_key_here")
        print("   - OPENAI_API_KEY=your_api_key_here")
        print("   - DASHSCOPE_API_KEY=your_api_key_here")
        print("\næ‚¨ä»ç„¶å¯ä»¥å¯åŠ¨ç•Œé¢ï¼Œä½†éœ€è¦é…ç½®APIå¯†é’¥æ‰èƒ½æ­£å¸¸ä½¿ç”¨ã€‚")

    # è‡ªåŠ¨æŸ¥æ‰¾å¯ç”¨ç«¯å£
    print("\n[PORT] æ£€æŸ¥ç«¯å£å¯ç”¨æ€§...")
    available_port = get_server_port(SERVER_PORT, SERVER_HOST)

    # åˆ›å»ºå¹¶å¯åŠ¨åº”ç”¨
    client = LLMClient()
    demo = client.create_interface()

    # å¯åŠ¨æœåŠ¡å™¨
    print(f"\n[LAUNCH] å¯åŠ¨WebæœåŠ¡å™¨...")
    print(f"   ä¸»æœº: {SERVER_HOST}")
    print(f"   ç«¯å£: {available_port if available_port else 'ç³»ç»Ÿåˆ†é…'}")
    print(f"   æµè§ˆå™¨å°†è‡ªåŠ¨æ‰“å¼€")
    print("=" * 60)

    demo.launch(
        server_name=SERVER_HOST,
        server_port=available_port,
        share=False,
        inbrowser=True,
        show_error=True
    )


if __name__ == "__main__":
    main()
